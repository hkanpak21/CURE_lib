package split

import (
	"fmt"
	"math"

	"github.com/tuneinsight/lattigo/v6/core/rlwe"
	"github.com/tuneinsight/lattigo/v6/schemes/ckks"
)

// Client performs forward and backward pass after receiving encrypted activations
func clientForwardAndBackward(heContext *HEContext, clientModel *ClientModel, encActivations []*rlwe.Ciphertext,
	labels []int, batchIndices []int) ([]*rlwe.Ciphertext, error) {

	batchSize := len(batchIndices)
	if batchSize == 0 {
		return nil, fmt.Errorf("empty batch")
	}

	// Check if activations are valid
	if len(encActivations) == 0 {
		return nil, fmt.Errorf("invalid input: empty encActivations")
	}

	// Get dimensions from configuration
	clientLayers := len(clientModel.Weights)
	if clientLayers == 0 {
		return nil, fmt.Errorf("client model has no layers")
	}

	// Input dimension for the client is the output of the server's last layer
	inputDim := clientModel.GetLayerInputDim(0)

	// Step 1: Receive & Decrypt server's activations
	// Each ciphertext represents a single image
	a1Transposed := make([][]float64, batchSize)

	// Process each image in the batch
	for i := 0; i < batchSize; i++ {
		// Decrypt the ciphertext for this image
		pt := heContext.decryptor.DecryptNew(encActivations[i])

		// Decode the plaintext - we get values in slots
		decoded := make([]float64, heContext.params.N()/2)
		heContext.encoder.Decode(pt, decoded)

		// Extract values for each neuron
		a1Transposed[i] = make([]float64, inputDim)
		for j := 0; j < inputDim; j++ {
			a1Transposed[i][j] = decoded[j]
		}
	}

	// Step 2: Forward Pass through Client's Layers
	// Store activations for each layer (including input)
	activations := make([][][]float64, clientLayers+1)
	activations[0] = a1Transposed // Input layer

	// Process each layer
	for l := 0; l < clientLayers; l++ {
		inputDim := clientModel.GetLayerInputDim(l)
		outputDim := clientModel.GetLayerOutputDim(l)

		// Initialize this layer's activations
		activations[l+1] = make([][]float64, batchSize)
		for i := range activations[l+1] {
			activations[l+1][i] = make([]float64, outputDim)

			// Compute linear combination: act = prev_act * W + b
			for j := 0; j < outputDim; j++ {
				activations[l+1][i][j] = clientModel.Biases[l][j] // Add bias

				for k := 0; k < inputDim; k++ {
					activations[l+1][i][j] += activations[l][i][k] * clientModel.GetWeight(l, k, j)
				}
			}

			// Apply ReLU activation if not the output layer
			if l < clientLayers-1 {
				for j := range activations[l+1][i] {
					if activations[l+1][i][j] < 0 {
						activations[l+1][i][j] = 0
					}
				}
			}
		}
	}

	// Output layer activations
	outputActivations := activations[clientLayers]

	// Step 3: Compute Loss (Cross-Entropy Loss)
	// Apply softmax and compute cross-entropy loss
	outputDim := clientModel.GetLayerOutputDim(clientLayers - 1)

	// For tracking softmax values for gradient computation
	softmaxValues := make([][]float64, batchSize)

	for i := 0; i < batchSize; i++ {
		// Apply softmax: exp(output) / sum(exp(output))
		maxVal := outputActivations[i][0]
		for j := 1; j < outputDim; j++ {
			if outputActivations[i][j] > maxVal {
				maxVal = outputActivations[i][j]
			}
		}

		expSum := 0.0
		expValues := make([]float64, outputDim)
		for j := 0; j < outputDim; j++ {
			expValues[j] = math.Exp(outputActivations[i][j] - maxVal)
			expSum += expValues[j]
		}

		// Compute softmax
		softmaxValues[i] = make([]float64, outputDim)
		for j := 0; j < outputDim; j++ {
			softmaxValues[i][j] = expValues[j] / expSum
		}

		// Cross-entropy loss computation is commented out as it's not used in the algorithm
		// but kept for reference and future logging purposes
		// trueLabel := labels[batchIndices[i]]
		// loss += -math.Log(softmaxValues[i][trueLabel])
	}
	// loss /= float64(batchSize)

	// Step 4: Compute Gradients (Backward)
	// Initialize arrays to store gradients for each layer
	dZ := make([][][]float64, clientLayers)
	dW := make([][][]float64, clientLayers)
	db := make([][]float64, clientLayers)

	// Output layer gradients (start backpropagation)
	outputLayerIdx := clientLayers - 1
	dZ[outputLayerIdx] = make([][]float64, batchSize)

	for i := range dZ[outputLayerIdx] {
		dZ[outputLayerIdx][i] = make([]float64, outputDim)

		// Ensure we have valid label indices for computing gradients
		labelIdx := 0 // Default to class 0 if index is out of bounds
		if i < len(batchIndices) {
			batchIdx := batchIndices[i]
			if batchIdx < len(labels) {
				labelIdx = labels[batchIdx]
				// Make sure labelIdx is valid for the output dimension
				if labelIdx >= outputDim {
					labelIdx = 0 // If label is invalid, default to class 0
				}
			}
		}

		for j := 0; j < outputDim; j++ {
			// Derivative of softmax cross-entropy is (softmax - one_hot_true)
			if j == labelIdx {
				// Softmax - 1.0 for true class
				dZ[outputLayerIdx][i][j] = softmaxValues[i][j] - 1.0
			} else {
				// Softmax for other classes
				dZ[outputLayerIdx][i][j] = softmaxValues[i][j]
			}
		}
	}

	// Backpropagate through each layer
	for l := clientLayers - 1; l >= 0; l-- {
		inputDim := clientModel.GetLayerInputDim(l)
		outputDim := clientModel.GetLayerOutputDim(l)

		// Compute weight gradients for this layer
		dW[l] = make([][]float64, inputDim)
		for i := 0; i < inputDim; i++ {
			// Skip if index is out of bounds for the current layer
			if i >= len(clientModel.Weights[l]) {
				fmt.Printf("Warning: Skipping out-of-bounds index i=%d for layer %d (weights dim: %d)\n",
					i, l, len(clientModel.Weights[l]))
				dW[l][i] = make([]float64, outputDim) // Still create the array to avoid nil references
				continue
			}

			dW[l][i] = make([]float64, outputDim)
			for j := 0; j < outputDim; j++ {
				for k := 0; k < batchSize; k++ {
					dW[l][i][j] += activations[l][k][i] * dZ[l][k][j]
				}
				dW[l][i][j] /= float64(batchSize)
			}
		}

		// Compute bias gradients for this layer
		db[l] = make([]float64, outputDim)
		for i := 0; i < outputDim; i++ {
			for j := 0; j < batchSize; j++ {
				db[l][i] += dZ[l][j][i]
			}
			db[l][i] /= float64(batchSize)
		}

		// Compute gradients for previous layer if not at input layer
		if l > 0 {
			prevLayerDim := clientModel.GetLayerInputDim(l - 1)
			dZ[l-1] = make([][]float64, batchSize)

			for i := range dZ[l-1] {
				dZ[l-1][i] = make([]float64, prevLayerDim)

				// For each neuron in the previous layer
				for j := 0; j < prevLayerDim; j++ {
					// For each neuron in the current layer
					for k := 0; k < outputDim; k++ {
						// Skip if k is out of bounds for the current layer
						if k >= len(clientModel.Weights[l][0]) {
							continue
						}

						// Skip if j is out of bounds for the current layer's weights
						if j >= len(clientModel.Weights[l]) {
							continue
						}

						// Use GetWeight which has bounds checking instead of direct array access
						weight := clientModel.GetWeight(l, j, k)
						dZ[l-1][i][j] += dZ[l][i][k] * weight
					}

					// Apply ReLU derivative if not the input layer
					if l > 1 { // Changed from l > 0 to l > 1 to avoid accessing non-existent activations
						// ReLU derivative: 0 if input <= 0, 1 otherwise
						if j < len(activations[l-1][i]) && activations[l-1][i][j] <= 0 {
							dZ[l-1][i][j] = 0
						}
					}
				}
			}
		}
	}

	// Step 5: Update Client's Weights
	// Update weights and biases for each layer
	for l := 0; l < clientLayers; l++ {
		inputDim := clientModel.GetLayerInputDim(l)
		outputDim := clientModel.GetLayerOutputDim(l)

		// Update weights
		for i := 0; i < inputDim; i++ {
			for j := 0; j < outputDim; j++ {
				newWeight := clientModel.GetWeight(l, i, j) - LearningRate*dW[l][i][j]
				clientModel.SetWeight(l, i, j, newWeight)
			}
		}

		// Update biases
		for j := 0; j < outputDim; j++ {
			clientModel.Biases[l][j] -= LearningRate * db[l][j]
		}
	}

	// Step 6: Prepare gradients for the server (gradients for the input layer)
	// First, convert dA1 to the format needed by the server
	inputGradients := make([][]float64, inputDim)
	for i := 0; i < inputDim; i++ {
		inputGradients[i] = make([]float64, batchSize)
		for j := 0; j < batchSize; j++ {
			inputGradients[i][j] = dZ[0][j][i]
		}
	}

	// Step 7: Pack and encrypt gradients to send back to server
	// Calculate how many neurons per ciphertext
	neuronsPerCT := calculateNeuronsPerCT(heContext.params.N()/2, batchSize, 64)
	numBlocks := (inputDim + neuronsPerCT - 1) / neuronsPerCT

	encGradBlk := make([]*rlwe.Ciphertext, numBlocks)
	slots := heContext.params.N() / 2

	// Process each block of neurons
	for b := 0; b < numBlocks; b++ {
		// Reuse this buffer across iterations - memory optimization
		scratch := make([]float64, slots)

		// Pack neurons for this block
		startNeuron := b * neuronsPerCT
		endNeuron := min(startNeuron+neuronsPerCT, inputDim)

		// Clear the scratch buffer
		for i := range scratch {
			scratch[i] = 0
		}

		// Pack each neuron's gradients for all examples in the batch
		for n := startNeuron; n < endNeuron; n++ {
			neuronOffset := (n - startNeuron) * batchSize

			// Copy this neuron's gradients for all examples
			for i := 0; i < batchSize; i++ {
				scratch[neuronOffset+i] = inputGradients[n][i]
			}
		}

		// Encode
		pt := ckks.NewPlaintext(heContext.params, heContext.params.MaxLevel())
		heContext.encoder.Encode(scratch, pt)

		// Encrypt
		encGrad, err := heContext.encryptor.EncryptNew(pt)
		if err != nil {
			return nil, fmt.Errorf("error encrypting gradients: %v", err)
		}

		encGradBlk[b] = encGrad
	}

	return encGradBlk, nil
}

// PerformEvaluation performs forward pass for evaluation without training
func PerformEvaluation(heContext *HEContext, clientModel *ClientModel, encActivations []*rlwe.Ciphertext,
	numImages int) ([]int, [][]float64, error) {

	// Get dimensions from configuration
	clientLayers := len(clientModel.Weights)
	if clientLayers == 0 {
		return nil, nil, fmt.Errorf("client model has no layers")
	}

	// Input dimension for the client is the output of the server's last layer
	inputDim := clientModel.GetLayerInputDim(0)
	numBlocks := len(encActivations)
	neuronsPerCT := inputDim / numBlocks

	// Step 1: Decrypt the server's encrypted activations
	a1 := make([][]float64, inputDim)

	for b := 0; b < numBlocks; b++ {
		// Decrypt the ciphertext for this block
		pt := heContext.decryptor.DecryptNew(encActivations[b])

		// Decode the plaintext
		decoded := make([]float64, heContext.params.N()/2)
		heContext.encoder.Decode(pt, decoded)

		// Extract values for each neuron in this block
		for n := 0; n < neuronsPerCT; n++ {
			neuronIdx := b*neuronsPerCT + n
			if neuronIdx < inputDim {
				a1[neuronIdx] = make([]float64, numImages)
				for i := 0; i < numImages; i++ {
					a1[neuronIdx][i] = decoded[n*numImages+i]
				}
			}
		}
	}

	// Transpose a1 to have shape [batchSize x inputDim]
	a1Transposed := make([][]float64, numImages)
	for i := range a1Transposed {
		a1Transposed[i] = make([]float64, inputDim)
		for j := 0; j < inputDim; j++ {
			a1Transposed[i][j] = a1[j][i]
		}
	}

	// Step 2: Forward Pass through Client's Layers
	// Store activations for each layer (including input)
	activations := make([][][]float64, clientLayers+1)
	activations[0] = a1Transposed // Input layer

	// Process each layer
	for l := 0; l < clientLayers; l++ {
		inputDim := clientModel.GetLayerInputDim(l)
		outputDim := clientModel.GetLayerOutputDim(l)

		// Initialize this layer's activations
		activations[l+1] = make([][]float64, numImages)
		for i := range activations[l+1] {
			activations[l+1][i] = make([]float64, outputDim)

			// Compute linear combination: act = prev_act * W + b
			for j := 0; j < outputDim; j++ {
				activations[l+1][i][j] = clientModel.Biases[l][j] // Add bias

				for k := 0; k < inputDim; k++ {
					activations[l+1][i][j] += activations[l][i][k] * clientModel.GetWeight(l, k, j)
				}
			}

			// Apply ReLU activation if not the output layer
			if l < clientLayers-1 {
				for j := range activations[l+1][i] {
					if activations[l+1][i][j] < 0 {
						activations[l+1][i][j] = 0
					}
				}
			}
		}
	}

	// Output layer activations
	outputActivations := activations[clientLayers]

	// Apply softmax to get probabilities
	predictions := make([]int, numImages)
	confidences := make([][]float64, numImages)

	for i := 0; i < numImages; i++ {
		// Apply softmax: exp(output) / sum(exp(output))
		maxVal := outputActivations[i][0]
		for j := 1; j < len(outputActivations[i]); j++ {
			if outputActivations[i][j] > maxVal {
				maxVal = outputActivations[i][j]
			}
		}

		expSum := 0.0
		expValues := make([]float64, len(outputActivations[i]))
		for j := 0; j < len(outputActivations[i]); j++ {
			expValues[j] = math.Exp(outputActivations[i][j] - maxVal)
			expSum += expValues[j]
		}

		// Compute softmax and find prediction
		confidences[i] = make([]float64, len(outputActivations[i]))
		maxProb := 0.0
		prediction := 0

		for j := 0; j < len(outputActivations[i]); j++ {
			confidences[i][j] = expValues[j] / expSum
			if confidences[i][j] > maxProb {
				maxProb = confidences[i][j]
				prediction = j
			}
		}

		predictions[i] = prediction
	}

	return predictions, confidences, nil
}

// Helper function to sum slots of a ciphertext for SIMD-based forward pass
func sumSlotsWithRotations(ctx *HEContext, ct *rlwe.Ciphertext, batchSize int) (*rlwe.Ciphertext, error) {
	// Sum all slots with log(batchSize) rotations
	result := ct.CopyNew()
	for i := 1; i < batchSize; i *= 2 {
		rotated := ct.CopyNew()
		if err := ctx.evaluator.Rotate(result, i, rotated); err != nil {
			return nil, fmt.Errorf("error in rotation: %v", err)
		}
		if err := ctx.evaluator.Add(result, rotated, result); err != nil {
			return nil, fmt.Errorf("error in addition: %v", err)
		}
	}
	return result, nil
}

// ServerBackwardAndUpdate performs server backward pass and weight updates
func serverBackwardAndUpdate(heContext *HEContext, serverModel *ServerModel, encGradients []*rlwe.Ciphertext,
	cachedInputs []*rlwe.Ciphertext, learningRate float64) error {
	// Delegate to packed update for efficiency
	return packedUpdate(heContext, serverModel, cachedInputs, encGradients, learningRate, len(cachedInputs))
}

// Packed update using SIMD optimizations
func packedUpdate(heContext *HEContext, serverModel *ServerModel, encInputs []*rlwe.Ciphertext,
	encGradients []*rlwe.Ciphertext, learningRate float64, batchSize int) error {

	// Convert server model to packed format
	heServerPacked, err := convertToPacked(serverModel, heContext)
	if err != nil {
		return fmt.Errorf("error converting to packed model: %v", err)
	}

	// Process each layer in the server model
	for l := 0; l < len(serverModel.Weights); l++ {
		inputDim := serverModel.GetLayerInputDim(l)
		outputDim := serverModel.GetLayerOutputDim(l)

		// Calculate number of blocks for the output dimension
		neuronsPerCT := heServerPacked.NeuronsPerCT
		outputBlocks := (outputDim + neuronsPerCT - 1) / neuronsPerCT

		// Use min to ensure we don't go out of bounds
		maxInputIdx := min(inputDim, len(encInputs))
		maxOutputIdx := min(outputBlocks, len(encGradients))

		// For each input dimension (limited by available inputs)
		for i := 0; i < maxInputIdx; i++ {
			// For each output block (limited by available gradients)
			for j := 0; j < maxOutputIdx; j++ {
				// Compute outer product of input and gradient
				// Expand input: duplicate each element to match with corresponding gradients
				expandedInput := encInputs[i].CopyNew()

				// Extract the j-th block of gradients
				gradBlock := encGradients[j].CopyNew()

				// Multiply expanded input with gradient block (element-wise)
				product := expandedInput.CopyNew()
				if err := heContext.evaluator.Mul(expandedInput, gradBlock, product); err != nil {
					return fmt.Errorf("error computing gradient product: %v", err)
				}

				// Rescale product
				if err := heContext.evaluator.Rescale(product, product); err != nil {
					return fmt.Errorf("error rescaling product: %v", err)
				}

				// Scale by learning rate (negative since we're doing gradient descent)
				scaled := product.CopyNew()
				if err := heContext.evaluator.Mul(product, -learningRate/float64(batchSize), scaled); err != nil {
					return fmt.Errorf("error scaling by learning rate: %v", err)
				}

				// Add to current weights
				if err := heContext.evaluator.Add(heServerPacked.W[l][i][j], scaled, heServerPacked.W[l][i][j]); err != nil {
					return fmt.Errorf("error updating weights: %v", err)
				}
			}
		}

		// Update biases (limited by available gradients)
		maxBiasIdx := min(len(heServerPacked.b[l]), len(encGradients))
		for j := 0; j < maxBiasIdx; j++ {
			// Scale gradient by learning rate (negative for gradient descent)
			scaledGrad := encGradients[j].CopyNew()
			if err := heContext.evaluator.Mul(encGradients[j], -learningRate/float64(batchSize), scaledGrad); err != nil {
				return fmt.Errorf("error scaling bias gradient: %v", err)
			}

			// Add to current biases
			if err := heContext.evaluator.Add(heServerPacked.b[l][j], scaledGrad, heServerPacked.b[l][j]); err != nil {
				return fmt.Errorf("error updating biases: %v", err)
			}
		}
	}

	// Extract updated weights back to the normal server model
	for l := 0; l < len(serverModel.Weights); l++ {
		updateModelFromHE(heContext, serverModel, heServerPacked, l, batchSize)
	}

	return nil
}

// Helper function to update a specific layer from the homomorphic encrypted version
func updateModelFromHE(heContext *HEContext, serverModel *ServerModel, heServer *HEServerPacked, layer int, batchSize int) {
	// Get dimensions
	inputDim := serverModel.GetLayerInputDim(layer)
	outputDim := serverModel.GetLayerOutputDim(layer)
	neuronsPerCT := heServer.NeuronsPerCT

	// Calculate number of blocks
	outputBlocks := (outputDim + neuronsPerCT - 1) / neuronsPerCT

	// Ensure we don't go out of bounds
	if layer >= len(serverModel.Weights) || layer >= len(heServer.W) {
		return
	}

	// Make sure inputDim matches actual dimensions of weights
	actualInputDim := min(inputDim, len(serverModel.Weights[layer]))

	// Temporary buffer for decoding
	slots := heContext.params.N() / 2
	plainVector := make([]float64, slots)

	// For each input neuron
	for i := 0; i < actualInputDim; i++ {
		// Skip if beyond the packed model's dimensions
		if i >= len(heServer.W[layer]) {
			continue
		}

		// For each output block
		actualBlocks := min(outputBlocks, len(heServer.W[layer][i]))
		for blk := 0; blk < actualBlocks; blk++ {
			// Decrypt the weight ciphertext
			pt := heContext.decryptor.DecryptNew(heServer.W[layer][i][blk])
			heContext.encoder.Decode(pt, plainVector)

			// Extract individual weights from the packed representation
			for j := 0; j < neuronsPerCT; j++ {
				outputIdx := blk*neuronsPerCT + j
				if outputIdx < outputDim && outputIdx < len(serverModel.Weights[layer][i]) {
					// Weight is at slot j
					serverModel.SetWeight(layer, i, outputIdx, plainVector[j])
				}
			}
		}
	}

	// Update biases
	// Ensure we don't go out of bounds with biases
	if layer >= len(serverModel.Biases) || layer >= len(heServer.b) {
		return
	}

	actualBiasBlocks := min(outputBlocks, len(heServer.b[layer]))
	for blk := 0; blk < actualBiasBlocks; blk++ {
		// Decrypt the bias ciphertext
		pt := heContext.decryptor.DecryptNew(heServer.b[layer][blk])
		heContext.encoder.Decode(pt, plainVector)

		// Extract individual biases
		for j := 0; j < neuronsPerCT; j++ {
			outputIdx := blk*neuronsPerCT + j
			if outputIdx < outputDim && outputIdx < len(serverModel.Biases[layer]) {
				// Bias is at slot j
				serverModel.Biases[layer][outputIdx] = plainVector[j]
			}
		}
	}
}
package split

import (
	"fmt"
)

// FunctionEfficiencyReport represents an assessment of a function's implementation
type FunctionEfficiencyReport struct {
	FunctionName     string
	UsesParallelism  bool
	UsesPacking      bool
	HasDummyOps      bool
	RecommendRemoval bool
	Reason           string
}

// IdentifyIneffectiveFunctions returns a list of functions that should be considered
// for removal due to lack of parallelization, packing, or containing dummy operations
func IdentifyIneffectiveFunctions() []FunctionEfficiencyReport {
	// This is a manual assessment of the functions in the codebase
	reports := []FunctionEfficiencyReport{
		{
			FunctionName:     "trainBatch",
			UsesParallelism:  false,
			UsesPacking:      false,
			HasDummyOps:      false,
			RecommendRemoval: true,
			Reason:           "Superseded by trainBatchWithTiming and trainBatchFullHomomorphic which have better instrumentation",
		},
		{
			FunctionName:     "trainModel",
			UsesParallelism:  false,
			UsesPacking:      false,
			HasDummyOps:      false,
			RecommendRemoval: true,
			Reason:           "Replaced by trainModelWithBatches which has better control and timing",
		},
		{
			FunctionName:     "packedUpdate",
			UsesParallelism:  false,
			UsesPacking:      true,
			HasDummyOps:      false,
			RecommendRemoval: true,
			Reason:           "Superseded by packedUpdateDirect which is more efficient",
		},
		{
			FunctionName:     "updateModelFromHE",
			UsesParallelism:  false,
			UsesPacking:      true,
			HasDummyOps:      false,
			RecommendRemoval: true,
			Reason:           "Replaced by updateCompleteModelFromHE which handles the entire model at once",
		},
	}

	return reports
}

// PrintFunctionReport prints the report of functions that should be considered for removal
func PrintFunctionReport() {
	reports := IdentifyIneffectiveFunctions()

	fmt.Println("\nFunctions Recommended for Removal:")
	fmt.Println("==================================")

	for _, report := range reports {
		fmt.Printf("Function: %s\n", report.FunctionName)
		fmt.Printf("  Uses Parallelism: %t\n", report.UsesParallelism)
		fmt.Printf("  Uses Packing: %t\n", report.UsesPacking)
		fmt.Printf("  Has Dummy Operations: %t\n", report.HasDummyOps)
		fmt.Printf("  Reason for Removal: %s\n\n", report.Reason)
	}

	fmt.Println("Note: These functions should be removed or refactored to improve performance and maintainability.")
}

// RemoveIneffectiveFunctions is a placeholder function that would actually remove
// the identified ineffective functions if implemented
func RemoveIneffectiveFunctions() {
	// This would be implemented with actual code refactoring tools
	// For now, it's a placeholder to remind developers which functions to remove

	fmt.Println("To remove ineffective functions:")
	fmt.Println("1. Identify all callers of these functions")
	fmt.Println("2. Replace calls with their more efficient alternatives")
	fmt.Println("3. Remove the function implementations")
	fmt.Println("4. Update tests to use the new functions")
	fmt.Println("5. Run the performance tests to verify improvements")
}
package split

import (
	"encoding/binary"
	"fmt"
	"os"
)

// DataPath represents the path to the MNIST data files
var DataPath = "/Users/halilibrahimkanpak/Documents/Coding/CURE_lib/data"

//go:generate bash -c "mkdir -p ./data && cd ./data && curl -O http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz && curl -O http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz && curl -O http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz && curl -O http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz && gzip -d *.gz || true"

// Function to read MNIST data
func readMNISTData() ([][]float64, []int, [][]float64, []int, error) {
	// Define file paths
	trainImagesPath := DataPath + "/train-images-idx3-ubyte"
	trainLabelsPath := DataPath + "/train-labels-idx1-ubyte"
	testImagesPath := DataPath + "/t10k-images-idx3-ubyte"
	testLabelsPath := DataPath + "/t10k-labels-idx1-ubyte"

	// Read training images
	trainImages, err := readMNISTImages(trainImagesPath)
	if err != nil {
		return nil, nil, nil, nil, fmt.Errorf("error reading training images: %v", err)
	}

	// Read training labels
	trainLabels, err := readMNISTLabels(trainLabelsPath)
	if err != nil {
		return nil, nil, nil, nil, fmt.Errorf("error reading training labels: %v", err)
	}

	// Read test images
	testImages, err := readMNISTImages(testImagesPath)
	if err != nil {
		return nil, nil, nil, nil, fmt.Errorf("error reading test images: %v", err)
	}

	// Read test labels
	testLabels, err := readMNISTLabels(testLabelsPath)
	if err != nil {
		return nil, nil, nil, nil, fmt.Errorf("error reading test labels: %v", err)
	}

	return trainImages, trainLabels, testImages, testLabels, nil
}

// Helper function to read MNIST images
func readMNISTImages(filename string) ([][]float64, error) {
	// Open the file
	file, err := os.Open(filename)
	if err != nil {
		return nil, err
	}
	defer file.Close()

	// Read the header
	header := make([]int32, 4)
	err = binary.Read(file, binary.BigEndian, &header)
	if err != nil {
		return nil, err
	}

	// Check the magic number
	if header[0] != 2051 {
		return nil, fmt.Errorf("invalid magic number: %d", header[0])
	}

	// Get number of images, rows, and columns
	numImages := int(header[1])
	numRows := int(header[2])
	numCols := int(header[3])
	numPixels := numRows * numCols

	// Read the image data
	imageData := make([]byte, numImages*numPixels)
	err = binary.Read(file, binary.BigEndian, imageData)
	if err != nil {
		return nil, err
	}

	// Convert to float64 array and normalize (0-1)
	images := make([][]float64, numImages)
	for i := 0; i < numImages; i++ {
		images[i] = make([]float64, numPixels)
		for j := 0; j < numPixels; j++ {
			images[i][j] = float64(imageData[i*numPixels+j]) / 255.0
		}
	}

	return images, nil
}

// Helper function to read MNIST labels
func readMNISTLabels(filename string) ([]int, error) {
	// Open the file
	file, err := os.Open(filename)
	if err != nil {
		return nil, err
	}
	defer file.Close()

	// Read the header
	header := make([]int32, 2)
	err = binary.Read(file, binary.BigEndian, &header)
	if err != nil {
		return nil, err
	}

	// Check the magic number
	if header[0] != 2049 {
		return nil, fmt.Errorf("invalid magic number: %d", header[0])
	}

	// Get number of labels
	numLabels := int(header[1])

	// Read the label data
	labelData := make([]byte, numLabels)
	err = binary.Read(file, binary.BigEndian, labelData)
	if err != nil {
		return nil, err
	}

	// Convert to int array
	labels := make([]int, numLabels)
	for i := 0; i < numLabels; i++ {
		labels[i] = int(labelData[i])
	}

	return labels, nil
}
package split

import (
	"fmt"
)

// Evaluates the model on test data and returns accuracy
func evaluateModel(heContext *HEContext, clientModel *ClientModel, serverModel *ServerModel,
	images [][]float64, labels []int) float64 {

	fmt.Println("Evaluating model on test data...")

	// Parameters for evaluation
	numExamples := 20 // Only evaluate on a small subset for testing
	correct := 0

	// Process individual examples
	for i := 0; i < numExamples; i++ {
		fmt.Printf("  Evaluating example %d/%d\n", i+1, numExamples)

		// Create indices array with just this example
		indices := []int{i}

		// Client prepares and encrypts the single image
		encInputs, err := clientPrepareAndEncryptBatch(heContext, images, indices)
		if err != nil {
			fmt.Printf("Error in client preparation: %v\n", err)
			continue
		}

		// Server performs forward pass
		encActivations, err := serverForwardPass(heContext, serverModel, encInputs)
		if err != nil {
			fmt.Printf("Error in server forward pass: %v\n", err)
			continue
		}

		// Client performs forward pass to get predictions
		predictions, _, err := PerformEvaluation(heContext, clientModel, encActivations, 1)
		if err != nil {
			fmt.Printf("Error in client evaluation: %v\n", err)
			continue
		}

		// Check if prediction is correct
		if predictions[0] == labels[i] {
			correct++
		}
	}

	// Calculate accuracy
	accuracy := float64(correct) / float64(numExamples)
	return accuracy
}

// EvaluateModelOnBatch evaluates the model on a batch of test examples
func EvaluateModelOnBatch(heContext *HEContext, clientModel *ClientModel, serverModel *ServerModel,
	images [][]float64, labels []int, batchIndices []int) (int, error) {

	batchSize := len(batchIndices)
	if batchSize == 0 {
		return 0, fmt.Errorf("empty batch")
	}

	// Client prepares and encrypts the batch of images
	encInputs, err := clientPrepareAndEncryptBatch(heContext, images, batchIndices)
	if err != nil {
		return 0, fmt.Errorf("error in client preparation: %v", err)
	}

	// Server performs forward pass
	encActivations, err := serverForwardPass(heContext, serverModel, encInputs)
	if err != nil {
		return 0, fmt.Errorf("error in server forward pass: %v", err)
	}

	// Client performs forward pass to get predictions
	predictions, _, err := PerformEvaluation(heContext, clientModel, encActivations, batchSize)
	if err != nil {
		return 0, fmt.Errorf("error in client evaluation: %v", err)
	}

	// Count correct predictions
	correct := 0
	for i := 0; i < batchSize; i++ {
		if predictions[i] == labels[batchIndices[i]] {
			correct++
		}
	}

	return correct, nil
}
package split

import (
	"fmt"
	"sync"

	"github.com/tuneinsight/lattigo/v6/core/rlwe"
	"github.com/tuneinsight/lattigo/v6/schemes/ckks"
)

// Client prepares and encrypts a batch of images for SIMD optimization
// Each image is encrypted into a separate ciphertext
func clientPrepareAndEncryptBatch(he *HEContext, imgs [][]float64, idx []int) ([]*rlwe.Ciphertext, error) {
	slots := he.params.N() / 2
	batch := len(idx)

	if batch == 0 {
		return nil, fmt.Errorf("empty batch")
	}

	// Create a ciphertext for each image in the batch
	encInputs := make([]*rlwe.Ciphertext, batch)

	// Create a buffer for encoding
	vec := make([]float64, slots)

	// Process each image in the batch
	for b := 0; b < batch; b++ {
		imgIdx := idx[b]
		img := imgs[imgIdx]
		pixelsPerImage := len(img)

		if pixelsPerImage > slots {
			return nil, fmt.Errorf("image too large for slot capacity: %d pixels > %d slots", pixelsPerImage, slots)
		}

		// Clear the buffer
		for i := range vec {
			vec[i] = 0
		}

		// Copy the image pixels into the vector
		for i := 0; i < pixelsPerImage; i++ {
			vec[i] = img[i]
		}

		// Encode the vector
		pt := ckks.NewPlaintext(he.params, he.params.MaxLevel())
		he.encoder.Encode(vec, pt)

		// Encrypt
		var err error
		encInputs[b], err = he.encryptor.EncryptNew(pt)
		if err != nil {
			return nil, fmt.Errorf("encryption error for image %d: %v", b, err)
		}
	}

	return encInputs, nil
}

// Cache for ReLU approximation coefficients
var (
	reluCoeffsMu sync.Mutex
	reluCoeffsC0 map[*HEContext]*rlwe.Plaintext
	reluCoeffsC1 map[*HEContext]*rlwe.Plaintext
	reluCoeffsC2 map[*HEContext]*rlwe.Plaintext
	relu05       map[*HEContext]*rlwe.Plaintext
)

func init() {
	reluCoeffsC0 = make(map[*HEContext]*rlwe.Plaintext)
	reluCoeffsC1 = make(map[*HEContext]*rlwe.Plaintext)
	reluCoeffsC2 = make(map[*HEContext]*rlwe.Plaintext)
	relu05 = make(map[*HEContext]*rlwe.Plaintext)
}

// Get cached ReLU approximation constants (using Chebyshev degree 2)
func getReLUCoeffs(he *HEContext) (*rlwe.Plaintext, *rlwe.Plaintext, *rlwe.Plaintext, *rlwe.Plaintext) {
	reluCoeffsMu.Lock()
	defer reluCoeffsMu.Unlock()

	// Check if coefficients already exist for this context
	if _, ok := reluCoeffsC0[he]; !ok {
		// Degree-2 Chebyshev approximation of ReLU: max(0, x) â‰ˆ C0 + C1*x + C2*x^2
		// Optimized coefficients for the range [-1, 1]
		c0 := scalarPlain(0.25, he.params, he.encoder)  // Constant term
		c1 := scalarPlain(0.5, he.params, he.encoder)   // Linear term
		c2 := scalarPlain(0.25, he.params, he.encoder)  // Quadratic term
		half := scalarPlain(0.5, he.params, he.encoder) // For 0.5 constant

		reluCoeffsC0[he] = c0
		reluCoeffsC1[he] = c1
		reluCoeffsC2[he] = c2
		relu05[he] = half
	}

	return reluCoeffsC0[he], reluCoeffsC1[he], reluCoeffsC2[he], relu05[he]
}

// Apply ReLU approximation using degree-2 Chebyshev polynomial
func applyReLU(he *HEContext, ct *rlwe.Ciphertext) (*rlwe.Ciphertext, error) {
	// Get cached coefficients
	c0, c1, c2, _ := getReLUCoeffs(he)

	// Create a copy for x^2
	ctSq := ct.CopyNew()

	// Calculate x^2
	if err := he.evaluator.Mul(ct, ct, ctSq); err != nil {
		return nil, fmt.Errorf("error in ReLU square calculation: %v", err)
	}

	// Relinearize after squaring
	if err := he.evaluator.Relinearize(ctSq, ctSq); err != nil {
		return nil, fmt.Errorf("error in ReLU relinearization: %v", err)
	}

	// Apply C2*x^2
	if err := he.evaluator.Mul(ctSq, c2, ctSq); err != nil {
		return nil, fmt.Errorf("error in ReLU quadratic term: %v", err)
	}

	// Apply C1*x to the original ct and store in result
	result := ct.CopyNew()
	if err := he.evaluator.Mul(result, c1, result); err != nil {
		return nil, fmt.Errorf("error in ReLU linear term: %v", err)
	}

	// Add C2*x^2 to C1*x
	if err := he.evaluator.Add(result, ctSq, result); err != nil {
		return nil, fmt.Errorf("error adding ReLU terms: %v", err)
	}

	// Add C0 (constant term)
	if err := he.evaluator.Add(result, c0, result); err != nil {
		return nil, fmt.Errorf("error adding ReLU constant term: %v", err)
	}

	// Rescale once at the end to maintain precision
	if err := he.evaluator.Rescale(result, result); err != nil {
		return nil, fmt.Errorf("error rescaling ReLU result: %v", err)
	}

	return result, nil
}

// Helper for dot product with power-of-two rotations
func dotPacked(he *HEContext, encImg *rlwe.Ciphertext, ptWRow []*rlwe.Plaintext, slotsPerPixel int) (*rlwe.Ciphertext, error) {
	// Create the accumulator as a copy of the first product
	acc := encImg.CopyNew()

	// Multiply with the first weight
	if err := he.evaluator.Mul(acc, ptWRow[0], acc); err != nil {
		return nil, fmt.Errorf("error in dot product multiplication: %v", err)
	}

	// For each remaining pixel
	for i := 1; i < len(ptWRow); i++ {
		// Rotate the input vector
		rotated := encImg.CopyNew()
		if err := he.evaluator.Rotate(encImg, i*slotsPerPixel, rotated); err != nil {
			return nil, fmt.Errorf("error rotating in dot product: %v", err)
		}

		// Multiply by the corresponding weight
		if err := he.evaluator.Mul(rotated, ptWRow[i], rotated); err != nil {
			return nil, fmt.Errorf("error in dot product multiplication: %v", err)
		}

		// Add to accumulator
		if err := he.evaluator.Add(acc, rotated, acc); err != nil {
			return nil, fmt.Errorf("error adding in dot product: %v", err)
		}
	}

	return acc, nil
}

// Parallel execution helper
func parallelFor(start, end int, fn func(int)) {
	var wg sync.WaitGroup
	numWorkers := NumWorkers

	// Adjust worker count if range is small
	if end-start < numWorkers {
		numWorkers = end - start
	}

	if numWorkers <= 1 {
		// Just run sequentially
		for i := start; i < end; i++ {
			fn(i)
		}
		return
	}

	// Divide work among workers
	wg.Add(numWorkers)
	chunkSize := (end - start + numWorkers - 1) / numWorkers

	for w := 0; w < numWorkers; w++ {
		go func(workerID int) {
			defer wg.Done()

			// Calculate this worker's range
			workerStart := start + workerID*chunkSize
			workerEnd := min(workerStart+chunkSize, end)

			// Process this worker's range
			for i := workerStart; i < workerEnd; i++ {
				fn(i)
			}
		}(w)
	}

	wg.Wait()
}

// Server performs forward pass on encrypted inputs with optimized parallel processing
// Each ciphertext contains a single image
func serverForwardPass(he *HEContext, serverModel *ServerModel, encInputs []*rlwe.Ciphertext) ([]*rlwe.Ciphertext, error) {
	// Check if input is valid
	if len(encInputs) == 0 || encInputs[0] == nil {
		return nil, fmt.Errorf("invalid input: empty or nil encInputs")
	}

	// Create a packed server model for SIMD operations
	heServer, err := convertToPacked(serverModel, he)
	if err != nil {
		return nil, fmt.Errorf("failed to convert to packed model: %v", err)
	}

	// Number of images in the batch
	batchSize := len(encInputs)

	// Process each image separately
	resultOutputs := make([]*rlwe.Ciphertext, batchSize)

	// For each image in the batch
	for batchIdx := 0; batchIdx < batchSize; batchIdx++ {
		// Process each layer in the server model
		currentLayerOutput := encInputs[batchIdx : batchIdx+1] // Slice with single ciphertext

		for l := 0; l < len(serverModel.Weights); l++ {
			inputDim := serverModel.GetLayerInputDim(l)
			outputDim := serverModel.GetLayerOutputDim(l)

			// Calculate the number of blocks needed for the output neurons
			neuronsPerCT := heServer.NeuronsPerCT
			numBlocks := (outputDim + neuronsPerCT - 1) / neuronsPerCT

			// Prepare the next layer activations
			nextLayer := make([]*rlwe.Ciphertext, numBlocks)

			// Create a mutex for thread-safe access to shared resources
			var mutex sync.Mutex

			// Process each block of neurons in parallel
			parallelFor(0, numBlocks, func(b int) {
				// Initialize with bias for this neuron block
				blockResult := heServer.b[l][b].CopyNew()

				// Get the input for this image
				encInput := currentLayerOutput[0]

				// For each input dimension, multiply by weight and add to accumulator
				for i := 0; i < inputDim; i++ {
					// Create a temporary ciphertext for this multiplication
					temp := encInput.CopyNew()

					// Multiply the input by the weight for this neuron block
					he.evaluator.Mul(temp, heServer.W[l][i][b], temp)

					// Relinearize
					he.evaluator.Relinearize(temp, temp)

					// Add to the accumulator
					he.evaluator.Add(blockResult, temp, blockResult)
				}

				// Apply ReLU approximation to this block's activation
				activatedBlock, err := applyReLU(he, blockResult)
				if err != nil {
					fmt.Printf("Error in ReLU for block %d: %v\n", b, err)
					return
				}

				// Safely store the result
				mutex.Lock()
				nextLayer[b] = activatedBlock
				mutex.Unlock()
			})

			// Update current layer for the next iteration
			currentLayerOutput = nextLayer
		}

		// Store the final output for this image
		resultOutputs[batchIdx] = currentLayerOutput[0]
	}

	return resultOutputs, nil
}
package split

import (
	"fmt"

	"github.com/tuneinsight/lattigo/v6/core/rlwe"
	"github.com/tuneinsight/lattigo/v6/schemes/ckks"
)

// HEContext holds all the necessary objects for homomorphic encryption
type HEContext struct {
	params    ckks.Parameters
	encoder   *ckks.Encoder
	encryptor *rlwe.Encryptor
	decryptor *rlwe.Decryptor
	evaluator *ckks.Evaluator
	sk        *rlwe.SecretKey
	pk        *rlwe.PublicKey
	rlk       *rlwe.RelinearizationKey
	rtks      []*rlwe.GaloisKey // Rotation keys
}

// Initialize HE parameters and generate keys
func initHE() (*HEContext, error) {
	// Use simple parameters with enough multiplicative depth for our operations
	paramsLiteral := ckks.ParametersLiteral{
		LogN:            12,                    // Ring degree: 2^12 = 4096 (smaller for faster testing)
		LogQ:            []int{40, 40, 40, 40}, // More conservative parameters
		LogP:            []int{45, 45},         // Special modulus for key switching
		LogDefaultScale: 30,                    // Scale 2^30
	}

	// Create parameters from literal
	params, err := ckks.NewParametersFromLiteral(paramsLiteral)
	if err != nil {
		return nil, fmt.Errorf("error creating CKKS parameters: %v", err)
	}

	// Generate keys
	kgen := rlwe.NewKeyGenerator(params)
	sk := kgen.GenSecretKeyNew()
	pk := kgen.GenPublicKeyNew(sk)

	// Generate relinearization keys (for relinearization)
	rlk := kgen.GenRelinearizationKeyNew(sk)

	// --- rotations we need (powers of two up to slots/2) ---
	rotations := []int{1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024}

	// Generate rotation keys for all needed rotations
	var rotKeys []*rlwe.GaloisKey
	for _, rot := range rotations {
		galEl := params.GaloisElement(rot)
		rotKey := kgen.GenGaloisKeyNew(galEl, sk)
		rotKeys = append(rotKeys, rotKey)
	}

	// Collect everything in a single EvaluationKey set
	evk := rlwe.NewMemEvaluationKeySet(rlk, rotKeys...)

	return &HEContext{
		params:    params,
		encoder:   ckks.NewEncoder(params),
		encryptor: rlwe.NewEncryptor(params, pk),
		decryptor: rlwe.NewDecryptor(params, sk),
		evaluator: ckks.NewEvaluator(params, evk),
		sk:        sk,
		pk:        pk,
		rlk:       rlk,
		rtks:      rotKeys,
	}, nil
}
package split

import (
	"github.com/tuneinsight/lattigo/v6/core/rlwe"
)

// InitHE initializes and returns a new homomorphic encryption context
func InitHE() (*HEContext, error) {
	return initHE()
}

// InitClientModel initializes a new client model with the given configuration
func InitClientModel(config *ModelConfig) *ClientModel {
	return initClientModel(config)
}

// InitServerModel initializes a new server model with the given configuration
func InitServerModel(config *ModelConfig) *ServerModel {
	return initServerModel(config)
}

// ClientPrepareAndEncryptBatch prepares and encrypts a batch of images for processing
func ClientPrepareAndEncryptBatch(he *HEContext, imgs [][]float64, idx []int) ([]*rlwe.Ciphertext, error) {
	return clientPrepareAndEncryptBatch(he, imgs, idx)
}

// ServerForwardPass performs the forward pass on the server side
func ServerForwardPass(he *HEContext, serverModel *ServerModel, encInputs []*rlwe.Ciphertext) ([]*rlwe.Ciphertext, error) {
	return serverForwardPass(he, serverModel, encInputs)
}

// ClientForwardAndBackward performs forward and backward passes on the client side
func ClientForwardAndBackward(heContext *HEContext, clientModel *ClientModel, encActivations []*rlwe.Ciphertext,
	labels []int, batchIndices []int) ([]*rlwe.Ciphertext, error) {
	return clientForwardAndBackward(heContext, clientModel, encActivations, labels, batchIndices)
}

// ServerBackwardAndUpdate performs the backward pass and updates the server model weights
func ServerBackwardAndUpdate(heContext *HEContext, serverModel *ServerModel, encGradients []*rlwe.Ciphertext,
	cachedInputs []*rlwe.Ciphertext, learningRate float64) error {
	return serverBackwardAndUpdate(heContext, serverModel, encGradients, cachedInputs, learningRate)
}
package split

import (
	"fmt"
	"math/rand"
	"os"

	"github.com/tuneinsight/lattigo/v6/core/rlwe"
	"github.com/tuneinsight/lattigo/v6/schemes/ckks"
)

// ClientModel represents the client-side part of the split learning model
type ClientModel struct {
	// Weights and biases for client layers
	Weights [][][]float64 // 3D array [layer][input][output]
	Biases  [][]float64   // Array of bias vectors for each layer
	Config  *ModelConfig  // Architecture configuration
}

// ServerModel represents the server-side part of the split learning model
type ServerModel struct {
	// Weights and biases for server layers
	Weights [][][]float64 // 3D array [layer][input][output]
	Biases  [][]float64   // Array of bias vectors for each layer
	Config  *ModelConfig  // Architecture configuration
}

// HEServerModel represents the fully homomorphic version of the server model
type HEServerModel struct {
	// Encrypted weights and biases
	Weights [][][]*rlwe.Ciphertext // Array of weight matrices for each layer
	Biases  [][]*rlwe.Ciphertext   // Array of bias vectors for each layer
	Config  *ModelConfig           // Architecture configuration
}

// HEServerPacked represents a packed version of the server model for SIMD operations
type HEServerPacked struct {
	// Packed weights as [layer][input_dim][output_dim/neuronsPerCT]
	W [][][]*rlwe.Ciphertext
	// Packed biases: [layer][output_dim/neuronsPerCT]
	b [][]*rlwe.Ciphertext
	// Number of neurons per ciphertext
	NeuronsPerCT int
	// Architecture configuration
	Config *ModelConfig
}

// Initialize a client model with random weights
func initClientModel(config *ModelConfig) *ClientModel {
	if config == nil {
		config = &ModelConfig{
			Arch:     DefaultArch,
			SplitIdx: 0,
		}
	}

	clientLayers := len(config.Arch) - config.SplitIdx - 1
	weights := make([][][]float64, clientLayers)
	biases := make([][]float64, clientLayers)

	// Initialize weights and biases for each layer
	for l := 0; l < clientLayers; l++ {
		// Get the actual dimensions from the architecture configuration
		// This ensures the dimensions match between GetLayerInputDim and weight array sizes
		inputDim := config.Arch[l+config.SplitIdx]
		outputDim := config.Arch[l+config.SplitIdx+1]

		// Initialize with scaled random weights (Xavier initialization)
		scale := 1.0 / float64(inputDim)
		weights[l] = make([][]float64, inputDim)
		for i := range weights[l] {
			weights[l][i] = make([]float64, outputDim)
			for j := range weights[l][i] {
				weights[l][i][j] = rand.NormFloat64() * scale
			}
		}

		biases[l] = make([]float64, outputDim)
		for i := range biases[l] {
			biases[l][i] = rand.NormFloat64() * 0.1
		}
	}

	return &ClientModel{
		Weights: weights,
		Biases:  biases,
		Config:  config,
	}
}

// Initialize a server model with random weights
func initServerModel(config *ModelConfig) *ServerModel {
	if config == nil {
		config = &ModelConfig{
			Arch:     DefaultArch,
			SplitIdx: 0,
		}
	}

	serverLayers := config.SplitIdx + 1
	weights := make([][][]float64, serverLayers-1) // No weights for input layer
	biases := make([][]float64, serverLayers-1)    // No biases for input layer

	// Initialize weights and biases for each layer
	for l := 0; l < serverLayers-1; l++ {
		inputDim := config.Arch[l]
		outputDim := config.Arch[l+1]

		// Initialize with scaled random weights (Xavier initialization)
		scale := 1.0 / float64(inputDim)
		weights[l] = make([][]float64, inputDim)
		for i := range weights[l] {
			weights[l][i] = make([]float64, outputDim)
			for j := range weights[l][i] {
				weights[l][i][j] = rand.NormFloat64() * scale
			}
		}

		biases[l] = make([]float64, outputDim)
		for i := range biases[l] {
			biases[l][i] = rand.NormFloat64() * 0.1
		}
	}

	return &ServerModel{
		Weights: weights,
		Biases:  biases,
		Config:  config,
	}
}

// Get the weight at specific layer, input, output indices
func (s *ServerModel) GetWeight(layer, input, output int) float64 {
	if layer < 0 || layer >= len(s.Weights) ||
		input < 0 || input >= len(s.Weights[layer]) ||
		output < 0 || output >= len(s.Weights[layer][input]) {
		fmt.Printf("Warning: Invalid weight index: [%d][%d][%d], weights dims: %d x %d x %d\n",
			layer, input, output, len(s.Weights),
			len(s.Weights[layer]), len(s.Weights[layer][input]))
		return 0
	}
	return s.Weights[layer][input][output]
}

// Set the weight at specific layer, input, output indices
func (s *ServerModel) SetWeight(layer, input, output int, value float64) {
	if layer < 0 || layer >= len(s.Weights) ||
		input < 0 || input >= len(s.Weights[layer]) ||
		output < 0 || output >= len(s.Weights[layer][input]) {
		fmt.Printf("Warning: Invalid weight index: [%d][%d][%d], weights dims: %d x %d x %d\n",
			layer, input, output, len(s.Weights),
			len(s.Weights[layer]), len(s.Weights[layer][input]))
		return
	}
	s.Weights[layer][input][output] = value
}

// Get the weight at specific layer, input, output indices
func (c *ClientModel) GetWeight(layer, input, output int) float64 {
	if layer < 0 || layer >= len(c.Weights) ||
		input < 0 || input >= len(c.Weights[layer]) ||
		output < 0 || output >= len(c.Weights[layer][input]) {
		fmt.Printf("Warning: Invalid weight index: [%d][%d][%d], weights dims: %d x %d x %d\n",
			layer, input, output, len(c.Weights),
			len(c.Weights[layer]), len(c.Weights[layer][input]))
		return 0
	}
	return c.Weights[layer][input][output]
}

// Set the weight at specific layer, input, output indices
func (c *ClientModel) SetWeight(layer, input, output int, value float64) {
	if layer < 0 || layer >= len(c.Weights) ||
		input < 0 || input >= len(c.Weights[layer]) ||
		output < 0 || output >= len(c.Weights[layer][input]) {
		fmt.Printf("Warning: Invalid weight index: [%d][%d][%d], weights dims: %d x %d x %d\n",
			layer, input, output, len(c.Weights),
			len(c.Weights[layer]), len(c.Weights[layer][input]))
		return
	}
	c.Weights[layer][input][output] = value
}

// GetLayerInputDim returns the input dimension for a given layer
func (s *ServerModel) GetLayerInputDim(layer int) int {
	return s.Config.Arch[layer]
}

// GetLayerOutputDim returns the output dimension for a given layer
func (s *ServerModel) GetLayerOutputDim(layer int) int {
	return s.Config.Arch[layer+1]
}

// GetLayerInputDim returns the input dimension for a given layer
func (c *ClientModel) GetLayerInputDim(layer int) int {
	return c.Config.Arch[layer+c.Config.SplitIdx]
}

// GetLayerOutputDim returns the output dimension for a given layer
func (c *ClientModel) GetLayerOutputDim(layer int) int {
	return c.Config.Arch[layer+c.Config.SplitIdx+1]
}

// convertToHomomorphicModel converts a standard ServerModel to a fully homomorphic HEServerModel
func convertToHomomorphicModel(serverModel *ServerModel, heContext *HEContext) (*HEServerModel, error) {
	serverLayers := len(serverModel.Weights)
	heModel := &HEServerModel{
		Weights: make([][][]*rlwe.Ciphertext, serverLayers),
		Biases:  make([][]*rlwe.Ciphertext, serverLayers),
		Config:  serverModel.Config,
	}

	// For each layer in the server model
	for l := 0; l < serverLayers; l++ {
		inputDim := serverModel.GetLayerInputDim(l)
		outputDim := serverModel.GetLayerOutputDim(l)

		// Allocate arrays for this layer
		heModel.Weights[l] = make([][]*rlwe.Ciphertext, inputDim)
		heModel.Biases[l] = make([]*rlwe.Ciphertext, outputDim)

		// Encrypt weights
		for i := 0; i < inputDim; i++ {
			heModel.Weights[l][i] = make([]*rlwe.Ciphertext, outputDim)
			for j := 0; j < outputDim; j++ {
				// Create plaintext
				pt := ckks.NewPlaintext(heContext.params, heContext.params.MaxLevel())

				// Create vector where all slots have the same weight value
				values := make([]float64, heContext.params.N()/2)
				for k := range values {
					values[k] = serverModel.Weights[l][i][j]
				}

				// Encode values
				heContext.encoder.Encode(values, pt)

				// Encrypt
				var err error
				heModel.Weights[l][i][j], err = heContext.encryptor.EncryptNew(pt)
				if err != nil {
					return nil, fmt.Errorf("error encrypting weight: %v", err)
				}
			}
		}

		// Encrypt biases
		for j := 0; j < outputDim; j++ {
			// Create plaintext
			pt := ckks.NewPlaintext(heContext.params, heContext.params.MaxLevel())

			// Create vector where all slots have the same bias value
			values := make([]float64, heContext.params.N()/2)
			for k := range values {
				values[k] = serverModel.Biases[l][j]
			}

			// Encode values
			heContext.encoder.Encode(values, pt)

			// Encrypt
			var err error
			heModel.Biases[l][j], err = heContext.encryptor.EncryptNew(pt)
			if err != nil {
				return nil, fmt.Errorf("error encrypting bias: %v", err)
			}
		}
	}

	return heModel, nil
}

// convertToPacked converts a ServerModel to a packed HEServerPacked for SIMD operations
func convertToPacked(server *ServerModel, he *HEContext) (*HEServerPacked, error) {
	serverLayers := len(server.Weights)

	// Calculate how many neurons to pack per ciphertext
	slots := he.params.N() / 2
	var neuronsPerCT int
	neuronsPerCT = calculateNeuronsPerCT(slots, BatchSize, 64) // Default max is 64 neurons

	packed := &HEServerPacked{
		W:            make([][][]*rlwe.Ciphertext, serverLayers),
		b:            make([][]*rlwe.Ciphertext, serverLayers),
		NeuronsPerCT: neuronsPerCT,
		Config:       server.Config,
	}

	// For each layer in the server model
	for l := 0; l < serverLayers; l++ {
		inputDim := server.GetLayerInputDim(l)
		outputDim := server.GetLayerOutputDim(l)

		// Calculate how many blocks needed
		numBlocks := (outputDim + neuronsPerCT - 1) / neuronsPerCT

		// Allocate arrays for this layer
		packed.W[l] = make([][]*rlwe.Ciphertext, inputDim)
		packed.b[l] = make([]*rlwe.Ciphertext, numBlocks)

		// helper alloc for encoding
		line := make([]float64, he.params.N()/2)

		// --- weights ---
		for i := 0; i < inputDim; i++ {
			packed.W[l][i] = make([]*rlwe.Ciphertext, numBlocks)

			for b := 0; b < numBlocks; b++ {
				// Clear the line buffer
				for k := range line {
					line[k] = 0
				}

				// Pack neurons for this block
				startNeuron := b * neuronsPerCT
				endNeuron := min(startNeuron+neuronsPerCT, outputDim)

				for n := startNeuron; n < endNeuron; n++ {
					neuronOffset := (n - startNeuron) * BatchSize
					weight := server.Weights[l][i][n]

					// Replicate the weight value across batch slots
					for batch := 0; batch < BatchSize; batch++ {
						line[neuronOffset+batch] = weight
					}
				}

				// Encode and encrypt
				pt := ckks.NewPlaintext(he.params, he.params.MaxLevel())
				he.encoder.Encode(line, pt)
				ct, err := he.encryptor.EncryptNew(pt)
				if err != nil {
					return nil, err
				}
				packed.W[l][i][b] = ct
			}
		}

		// --- biases ---
		for b := 0; b < numBlocks; b++ {
			// Clear the line buffer
			for k := range line {
				line[k] = 0
			}

			// Pack biases for this block
			startNeuron := b * neuronsPerCT
			endNeuron := min(startNeuron+neuronsPerCT, outputDim)

			for n := startNeuron; n < endNeuron; n++ {
				neuronOffset := (n - startNeuron) * BatchSize
				bias := server.Biases[l][n]

				// Replicate the bias value across batch slots
				for batch := 0; batch < BatchSize; batch++ {
					line[neuronOffset+batch] = bias
				}
			}

			// Encode and encrypt
			pt := ckks.NewPlaintext(he.params, he.params.MaxLevel())
			he.encoder.Encode(line, pt)
			ct, err := he.encryptor.EncryptNew(pt)
			if err != nil {
				return nil, err
			}
			packed.b[l][b] = ct
		}
	}

	return packed, nil
}

// saveModel saves client and server models to files
func saveModel(clientModel *ClientModel, serverModel *ServerModel, clientPath, serverPath string) error {
	// Create client model file
	clientFile, err := os.Create(clientPath)
	if err != nil {
		return fmt.Errorf("failed to create client model file: %v", err)
	}
	defer clientFile.Close()

	// Create server model file
	serverFile, err := os.Create(serverPath)
	if err != nil {
		return fmt.Errorf("failed to create server model file: %v", err)
	}
	defer serverFile.Close()

	// Save client model
	// First, save architecture and split point
	fmt.Fprintf(clientFile, "%d %d\n", len(clientModel.Config.Arch), clientModel.Config.SplitIdx)
	for _, dim := range clientModel.Config.Arch {
		fmt.Fprintf(clientFile, "%d ", dim)
	}
	fmt.Fprintln(clientFile)

	// Then save weights and biases for each layer
	fmt.Fprintf(clientFile, "%d\n", len(clientModel.Weights)) // Number of layers
	for l := 0; l < len(clientModel.Weights); l++ {
		inputDim := clientModel.GetLayerInputDim(l)
		outputDim := clientModel.GetLayerOutputDim(l)

		// Save dimensions
		fmt.Fprintf(clientFile, "%d %d\n", inputDim, outputDim)

		// Save weights
		for i := 0; i < inputDim; i++ {
			for j := 0; j < outputDim; j++ {
				fmt.Fprintf(clientFile, "%f ", clientModel.Weights[l][i][j])
			}
			fmt.Fprintln(clientFile)
		}

		// Save biases
		for j := 0; j < outputDim; j++ {
			fmt.Fprintf(clientFile, "%f ", clientModel.Biases[l][j])
		}
		fmt.Fprintln(clientFile)
	}

	// Save server model
	// First, save architecture and split point
	fmt.Fprintf(serverFile, "%d %d\n", len(serverModel.Config.Arch), serverModel.Config.SplitIdx)
	for _, dim := range serverModel.Config.Arch {
		fmt.Fprintf(serverFile, "%d ", dim)
	}
	fmt.Fprintln(serverFile)

	// Then save weights and biases for each layer
	fmt.Fprintf(serverFile, "%d\n", len(serverModel.Weights)) // Number of layers
	for l := 0; l < len(serverModel.Weights); l++ {
		inputDim := serverModel.GetLayerInputDim(l)
		outputDim := serverModel.GetLayerOutputDim(l)

		// Save dimensions
		fmt.Fprintf(serverFile, "%d %d\n", inputDim, outputDim)

		// Save weights
		for i := 0; i < inputDim; i++ {
			for j := 0; j < outputDim; j++ {
				fmt.Fprintf(serverFile, "%f ", serverModel.Weights[l][i][j])
			}
			fmt.Fprintln(serverFile)
		}

		// Save biases
		for j := 0; j < outputDim; j++ {
			fmt.Fprintf(serverFile, "%f ", serverModel.Biases[l][j])
		}
		fmt.Fprintln(serverFile)
	}

	return nil
}

// loadModel loads client and server models from files
func loadModel(clientPath, serverPath string) (*ClientModel, *ServerModel, error) {
	// Open client model file
	clientFile, err := os.Open(clientPath)
	if err != nil {
		return nil, nil, fmt.Errorf("failed to open client model file: %v", err)
	}
	defer clientFile.Close()

	// Open server model file
	serverFile, err := os.Open(serverPath)
	if err != nil {
		return nil, nil, fmt.Errorf("failed to open server model file: %v", err)
	}
	defer serverFile.Close()

	// Load client model
	// First, load architecture and split point
	var archLen, splitIdx int
	if _, err := fmt.Fscanf(clientFile, "%d %d\n", &archLen, &splitIdx); err != nil {
		return nil, nil, fmt.Errorf("failed to read client model header: %v", err)
	}

	// Read architecture
	arch := make([]int, archLen)
	for i := 0; i < archLen; i++ {
		if _, err := fmt.Fscanf(clientFile, "%d ", &arch[i]); err != nil {
			return nil, nil, fmt.Errorf("failed to read architecture: %v", err)
		}
	}
	fmt.Fscanln(clientFile) // Consume newline

	// Create model config
	config := &ModelConfig{
		Arch:     arch,
		SplitIdx: splitIdx,
	}

	// Read number of layers
	var clientLayers int
	if _, err := fmt.Fscanf(clientFile, "%d\n", &clientLayers); err != nil {
		return nil, nil, fmt.Errorf("failed to read number of layers: %v", err)
	}

	// Create client model
	clientModel := &ClientModel{
		Weights: make([][][]float64, clientLayers),
		Biases:  make([][]float64, clientLayers),
		Config:  config,
	}

	// Read weights and biases for each layer
	for l := 0; l < clientLayers; l++ {
		var inputDim, outputDim int
		if _, err := fmt.Fscanf(clientFile, "%d %d\n", &inputDim, &outputDim); err != nil {
			return nil, nil, fmt.Errorf("failed to read layer dimensions: %v", err)
		}

		// Read weights
		clientModel.Weights[l] = make([][]float64, inputDim)
		for i := 0; i < inputDim; i++ {
			clientModel.Weights[l][i] = make([]float64, outputDim)
			for j := 0; j < outputDim; j++ {
				if _, err := fmt.Fscanf(clientFile, "%f ", &clientModel.Weights[l][i][j]); err != nil {
					return nil, nil, fmt.Errorf("failed to read weight: %v", err)
				}
			}
			fmt.Fscanln(clientFile) // Consume newline
		}

		// Read biases
		clientModel.Biases[l] = make([]float64, outputDim)
		for j := 0; j < outputDim; j++ {
			if _, err := fmt.Fscanf(clientFile, "%f ", &clientModel.Biases[l][j]); err != nil {
				return nil, nil, fmt.Errorf("failed to read bias: %v", err)
			}
		}
		fmt.Fscanln(clientFile) // Consume newline
	}

	// Load server model
	// First, load architecture and split point (but use the same config)
	if _, err := fmt.Fscanf(serverFile, "%d %d\n", &archLen, &splitIdx); err != nil {
		return nil, nil, fmt.Errorf("failed to read server model header: %v", err)
	}

	// Skip architecture
	for i := 0; i < archLen; i++ {
		var dummy int
		if _, err := fmt.Fscanf(serverFile, "%d ", &dummy); err != nil {
			return nil, nil, fmt.Errorf("failed to skip architecture: %v", err)
		}
	}
	fmt.Fscanln(serverFile) // Consume newline

	// Read number of layers
	var serverLayers int
	if _, err := fmt.Fscanf(serverFile, "%d\n", &serverLayers); err != nil {
		return nil, nil, fmt.Errorf("failed to read number of layers: %v", err)
	}

	// Create server model
	serverModel := &ServerModel{
		Weights: make([][][]float64, serverLayers),
		Biases:  make([][]float64, serverLayers),
		Config:  config,
	}

	// Read weights and biases for each layer
	for l := 0; l < serverLayers; l++ {
		var inputDim, outputDim int
		if _, err := fmt.Fscanf(serverFile, "%d %d\n", &inputDim, &outputDim); err != nil {
			return nil, nil, fmt.Errorf("failed to read layer dimensions: %v", err)
		}

		// Read weights
		serverModel.Weights[l] = make([][]float64, inputDim)
		for i := 0; i < inputDim; i++ {
			serverModel.Weights[l][i] = make([]float64, outputDim)
			for j := 0; j < outputDim; j++ {
				if _, err := fmt.Fscanf(serverFile, "%f ", &serverModel.Weights[l][i][j]); err != nil {
					return nil, nil, fmt.Errorf("failed to read weight: %v", err)
				}
			}
			fmt.Fscanln(serverFile) // Consume newline
		}

		// Read biases
		serverModel.Biases[l] = make([]float64, outputDim)
		for j := 0; j < outputDim; j++ {
			if _, err := fmt.Fscanf(serverFile, "%f ", &serverModel.Biases[l][j]); err != nil {
				return nil, nil, fmt.Errorf("failed to read bias: %v", err)
			}
		}
		fmt.Fscanln(serverFile) // Consume newline
	}

	return clientModel, serverModel, nil
}
package split

import (
	"encoding/json"
	"fmt"
)

// MNIST dataset dimensions
const (
	MnistRows     = 28
	MnistCols     = 28
	MnistPixels   = MnistRows * MnistCols // 784
	MnistTrainNum = 60000
	MnistTestNum  = 10000
	NumClasses    = 10
)

// Network architecture dimensions
const (
	InputDim   = MnistPixels // 784
	HiddenDim1 = 128
	HiddenDim2 = 32
	OutputDim  = NumClasses // 10
)

// We pack 64 hidden neurons per ciphertext.
// Works for N=4096 and any batch B â‰¤ 32   (64Ã—32 = 2048 slots)
const (
	NeuronsPerCT = 64 // â˜… SIMD-weights
)

// Training parameters
const (
	Epochs       = 1
	LearningRate = 0.01
	NumWorkers   = 4 // For parallel operations
)

// Default batch size (can be overridden by command-line flag)
var BatchSize = 8 // Reduced from 64 for faster testing

// Default architecture when not specified
var DefaultArch = []int{MnistPixels, 128, 32, NumClasses}

// ModelConfig holds the model architecture and split point
type ModelConfig struct {
	Arch     []int `json:"arch"`     // Network layer dimensions
	SplitIdx int   `json:"splitIdx"` // Index of the split point
}

// ParseConfig parses a JSON string into a ModelConfig
func ParseConfig(jsonStr string) (*ModelConfig, error) {
	var config ModelConfig
	if err := json.Unmarshal([]byte(jsonStr), &config); err != nil {
		return nil, err
	}
	return &config, nil
}

// Validate checks if the model configuration is valid
func (mc *ModelConfig) Validate() bool {
	// Must have at least 2 layers (input and output)
	if mc == nil || len(mc.Arch) < 2 {
		return false
	}

	// Split index must be between 0 and len(Arch)-2
	// 0 means server has no layers (client does all work)
	// len(Arch)-2 means client has just the output layer
	if mc.SplitIdx < 0 || mc.SplitIdx >= len(mc.Arch)-1 {
		return false
	}

	return true
}

// RunConfig holds the runtime configuration for training/evaluation
type RunConfig struct {
	Mode       string       // 'train' or 'eval'
	NumBatches int          // Number of batches for training
	BatchSize  int          // Mini-batch size
	FullyHE    bool         // Use fully homomorphic backpropagation
	FullySIMD  bool         // Use fully optimized SIMD training (keeps model encrypted)
	SaveModels bool         // Save models after training
	ClientPath string       // Path to save/load client model
	ServerPath string       // Path to save/load server model
	ModelCfg   *ModelConfig // Network architecture configuration
}

// calculateNeuronsPerCT determines how many neurons can be packed into one ciphertext
func calculateNeuronsPerCT(slots, batchSize, maxPerCT int) int {
	// Maximum neurons that can fit given the batch size
	maxFit := slots / batchSize

	// Cap at a reasonable value to avoid numeric issues
	if maxFit > maxPerCT {
		return maxPerCT
	}

	// Ensure at least 1 neuron per ciphertext
	if maxFit < 1 {
		return 1
	}

	return maxFit
}

// ApplyConfig applies the configuration to the global variables
func ApplyConfig(config *RunConfig) {
	if config == nil {
		return
	}

	// Update BatchSize if specified
	if config.BatchSize > 0 {
		BatchSize = config.BatchSize
	}
}

// PrintConfig prints the current configuration details
func PrintConfig(config *RunConfig) {
	fmt.Println("\nConfiguration Details:")
	fmt.Printf("  Batch Size: %d\n", BatchSize)

	// Print training mode
	if config != nil {
		fmt.Printf("  Training Mode: ")
		if config.FullyHE {
			fmt.Println("Fully Homomorphic")
		} else if config.FullySIMD {
			fmt.Println("Fully Optimized SIMD")
		} else {
			fmt.Println("Standard")
		}
	}

	if config != nil && config.ModelCfg != nil {
		fmt.Println("  Architecture:")
		fmt.Printf("    Layers: %v\n", config.ModelCfg.Arch)
		fmt.Printf("    Split Index: %d\n", config.ModelCfg.SplitIdx)
		fmt.Printf("    Server Layers: %d\n", config.ModelCfg.SplitIdx+1)
		fmt.Printf("    Client Layers: %d\n", len(config.ModelCfg.Arch)-config.ModelCfg.SplitIdx-1)
	} else {
		fmt.Println("  Architecture: Using Default")
		fmt.Printf("    Layers: %v\n", DefaultArch)
	}
	fmt.Println("")
}
package split

import (
	"fmt"
	"math/rand"
	"sync"
	"testing"
	"time"

	"github.com/tuneinsight/lattigo/v6/core/rlwe"
	"github.com/tuneinsight/lattigo/v6/schemes/ckks"
)

// TestPerformance runs performance tests on key operations
func TestPerformance(t *testing.T) {
	// Set parameters for testing - use smaller numbers for testing
	const (
		numSamples   = 2       // Reduced from 10 to prevent out of range errors
		batchSize    = 4       // Reduced from 8 to prevent out of range errors
		imageSize    = 28 * 28 // MNIST image size
		numClasses   = 10      // Number of output classes
		learningRate = 0.01    // Learning rate for training
	)

	// Create a minimal but realistic architecture
	testArch := []int{imageSize, 128, 32, numClasses} // Classic MNIST architecture
	splitIdx := 1                                     // Split after first hidden layer

	config := &ModelConfig{
		Arch:     testArch,
		SplitIdx: splitIdx,
	}

	// Initialize HE context
	fmt.Println("Initializing HE context...")
	startHE := time.Now()
	heContext, err := InitHE()
	elapsedHE := time.Since(startHE)
	if err != nil {
		t.Fatalf("Failed to initialize HE context: %v", err)
	}
	fmt.Printf("HE context initialized in %v\n", elapsedHE)

	// Initialize models
	fmt.Println("Initializing models...")
	startClientModel := time.Now()
	clientModel := InitClientModel(config)
	elapsedClientModel := time.Since(startClientModel)
	fmt.Printf("Client model initialized in %v\n", elapsedClientModel)

	startServerModel := time.Now()
	serverModel := InitServerModel(config)
	elapsedServerModel := time.Since(startServerModel)
	fmt.Printf("Server model initialized in %v\n", elapsedServerModel)

	// Generate random sample data - generate more data than we need
	fmt.Println("Generating sample data...")
	totalImages := numSamples * batchSize
	images := make([][]float64, totalImages)
	labels := make([]int, totalImages)
	for i := range images {
		images[i] = make([]float64, imageSize)
		for j := range images[i] {
			images[i][j] = rand.Float64() // Random pixel values between 0 and 1
		}
		labels[i] = rand.Intn(numClasses) // Random label
	}

	// Store results for each operation
	type OperationTiming struct {
		Name        string
		Times       []time.Duration
		AverageTime time.Duration
	}

	timings := make([]OperationTiming, 4)
	timings[0].Name = "ClientPrepareAndEncryptBatch"
	timings[1].Name = "ServerForwardPass"
	timings[2].Name = "ClientForwardAndBackward"
	timings[3].Name = "ServerBackwardAndUpdate"

	// Run the tests
	fmt.Println("\nRunning performance tests...")

	var encInputsCache [][]*rlwe.Ciphertext
	var encActivationsCache [][]*rlwe.Ciphertext
	var encGradientsCache [][]*rlwe.Ciphertext

	// Save batch indices for later use with packed operations
	var firstBatchIndices []int

	// For each sample
	for s := 0; s < numSamples; s++ {
		fmt.Printf("Sample %d/%d\n", s+1, numSamples)

		// Get batch indices for this sample
		startIdx := s * batchSize
		endIdx := startIdx + batchSize

		// Ensure indices don't go out of bounds
		if endIdx > totalImages {
			endIdx = totalImages
		}

		// Create batch indices
		batchIndices := make([]int, endIdx-startIdx)
		for i := 0; i < len(batchIndices); i++ {
			batchIndices[i] = startIdx + i
		}

		// Save the first batch indices for later use
		if s == 0 {
			firstBatchIndices = make([]int, len(batchIndices))
			copy(firstBatchIndices, batchIndices)
		}

		// Skip if batch is empty
		if len(batchIndices) == 0 {
			fmt.Println("  Skipping empty batch")
			continue
		}

		fmt.Printf("  Processing batch with %d images\n", len(batchIndices))

		// 1. Client prepare and encrypt batch
		start := time.Now()
		encInputs, err := ClientPrepareAndEncryptBatch(heContext, images, batchIndices)
		elapsed := time.Since(start)
		if err != nil {
			t.Fatalf("ClientPrepareAndEncryptBatch failed: %v", err)
		}
		timings[0].Times = append(timings[0].Times, elapsed)
		fmt.Printf("  ClientPrepareAndEncryptBatch: %v\n", elapsed)
		encInputsCache = append(encInputsCache, encInputs)

		// 2. Server forward pass
		start = time.Now()
		encActivations, err := ServerForwardPass(heContext, serverModel, encInputs)
		elapsed = time.Since(start)
		if err != nil {
			t.Fatalf("ServerForwardPass failed: %v", err)
		}
		timings[1].Times = append(timings[1].Times, elapsed)
		fmt.Printf("  ServerForwardPass: %v\n", elapsed)
		encActivationsCache = append(encActivationsCache, encActivations)

		// 3. Client forward and backward
		start = time.Now()
		encGradients, err := ClientForwardAndBackward(heContext, clientModel, encActivations, labels[startIdx:endIdx], batchIndices)
		elapsed = time.Since(start)
		if err != nil {
			t.Fatalf("ClientForwardAndBackward failed: %v", err)
		}
		timings[2].Times = append(timings[2].Times, elapsed)
		fmt.Printf("  ClientForwardAndBackward: %v\n", elapsed)
		encGradientsCache = append(encGradientsCache, encGradients)

		// 4. Server backward and update
		start = time.Now()
		err = ServerBackwardAndUpdate(heContext, serverModel, encGradients, encInputs, learningRate)
		elapsed = time.Since(start)
		if err != nil {
			t.Fatalf("ServerBackwardAndUpdate failed: %v", err)
		}
		timings[3].Times = append(timings[3].Times, elapsed)
		fmt.Printf("  ServerBackwardAndUpdate: %v\n", elapsed)
	}

	// Calculate and print averages
	fmt.Println("\nPerformance Summary:")
	for i := range timings {
		var total time.Duration
		for _, t := range timings[i].Times {
			total += t
		}
		if len(timings[i].Times) > 0 {
			timings[i].AverageTime = total / time.Duration(len(timings[i].Times))
			fmt.Printf("%s: Avg %v\n", timings[i].Name, timings[i].AverageTime)
		} else {
			fmt.Printf("%s: No measurements\n", timings[i].Name)
		}
	}

	// Test the SIMD optimized paths
	fmt.Println("\nTesting SIMD-optimized operations...")

	// Test packed server model conversion
	fmt.Println("Converting to packed server model...")
	start := time.Now()
	packedServer, err := convertToPacked(serverModel, heContext)
	elapsed := time.Since(start)
	if err != nil {
		t.Fatalf("Failed to convert to packed server model: %v", err)
	}
	fmt.Printf("Packed server model conversion: %v\n", elapsed)

	// Test server forward pass with packed model
	if len(encInputsCache) > 0 {
		fmt.Println("Testing serverForwardPassPacked...")
		start = time.Now()
		packedActivations, err := serverForwardPassPacked(heContext, packedServer, encInputsCache[0])
		elapsed = time.Since(start)
		if err != nil {
			t.Fatalf("serverForwardPassPacked failed: %v", err)
		}
		fmt.Printf("serverForwardPassPacked: %v\n", elapsed)

		// Just to avoid unused variable warning
		if len(packedActivations) > 0 {
			fmt.Printf("  Processed %d packed activations\n", len(packedActivations))
		}

		// Test packed update
		if len(encGradientsCache) > 0 && len(firstBatchIndices) > 0 {
			fmt.Println("Testing packedUpdateDirect...")
			start = time.Now()
			err = packedUpdateDirect(heContext, packedServer, encInputsCache[0], encGradientsCache[0], learningRate, len(firstBatchIndices))
			elapsed = time.Since(start)
			if err != nil {
				t.Fatalf("packedUpdateDirect failed: %v", err)
			}
			fmt.Printf("packedUpdateDirect: %v\n", elapsed)
		}
	}

	// Test optimized full SIMD training
	fmt.Println("\nTesting full SIMD training cycle...")
	// This simulates one epoch of training with the optimized SIMD path
	if totalImages > 0 {
		simdBatchSize := 2 // Use smaller batch for quick test
		maxBatches := 1    // Just do one batch for testing
		simdTotalSize := simdBatchSize * maxBatches

		// Make sure we have enough data
		if simdTotalSize > totalImages {
			simdTotalSize = totalImages
			maxBatches = simdTotalSize / simdBatchSize
			if maxBatches == 0 {
				maxBatches = 1
				simdBatchSize = simdTotalSize
			}
		}

		start = time.Now()
		trainModelFullSIMD(heContext, clientModel, serverModel,
			images[:simdTotalSize], labels[:simdTotalSize],
			1, simdBatchSize, learningRate, maxBatches)
		elapsed = time.Since(start)
		fmt.Printf("Full SIMD training cycle (%d batches): %v\n", maxBatches, elapsed)
	}
}

// TestParallelExecution verifies that parallelization is working correctly
func TestParallelExecution(t *testing.T) {
	const items = 100
	const expectedSum = items * (items - 1) / 2 // Sum of numbers 0 to items-1

	// Create a test array
	array := make([]int, items)
	for i := range array {
		array[i] = i
	}

	// Create a result array to store processed values
	result := make([]int, items)
	var mu sync.Mutex
	sum := 0

	// Use the parallelFor function
	start := time.Now()
	parallelFor(0, items, func(i int) {
		// Simulate some work
		time.Sleep(time.Millisecond)
		result[i] = array[i]

		// Update sum safely
		mu.Lock()
		sum += array[i]
		mu.Unlock()
	})
	elapsed := time.Since(start)

	// Verify results
	for i := 0; i < items; i++ {
		if result[i] != i {
			t.Errorf("Parallel execution error: result[%d] = %d, expected %d", i, result[i], i)
		}
	}

	if sum != expectedSum {
		t.Errorf("Parallel execution error: sum = %d, expected %d", sum, expectedSum)
	}

	// Test without parallelization
	sum = 0
	start = time.Now()
	for i := 0; i < items; i++ {
		time.Sleep(time.Millisecond)
		sum += array[i]
	}
	elapsedSerial := time.Since(start)

	fmt.Printf("Parallel execution: %v, Serial execution: %v\n", elapsed, elapsedSerial)
	if NumWorkers > 1 && elapsed >= elapsedSerial {
		// Only warn if we expect parallelization (NumWorkers > 1)
		t.Logf("Warning: Parallel execution (%v) was not faster than serial execution (%v)",
			elapsed, elapsedSerial)
	}
}

// TestReLUApproximation tests the correctness of the ReLU approximation
func TestReLUApproximation(t *testing.T) {
	// Initialize HE context
	heContext, err := InitHE()
	if err != nil {
		t.Fatalf("Failed to initialize HE context: %v", err)
	}

	// Test values to encrypt
	testValues := []float64{-2.0, -1.0, -0.5, 0.0, 0.5, 1.0, 2.0}
	slots := heContext.params.N() / 2
	vec := make([]float64, slots)

	// Set test values in first slots
	for i, val := range testValues {
		if i < slots {
			vec[i] = val
		}
	}

	// Encrypt
	pt := ckks.NewPlaintext(heContext.params, heContext.params.MaxLevel())
	heContext.encoder.Encode(vec, pt)

	ct, err := heContext.encryptor.EncryptNew(pt)
	if err != nil {
		t.Fatalf("Encryption failed: %v", err)
	}

	// Apply ReLU approximation
	start := time.Now()
	ctReLU, err := applyReLU(heContext, ct)
	elapsed := time.Since(start)
	if err != nil {
		t.Fatalf("ReLU approximation failed: %v", err)
	}
	fmt.Printf("ReLU approximation time: %v\n", elapsed)

	// Decrypt and check results
	ptResult := heContext.decryptor.DecryptNew(ctReLU)
	resultVec := make([]float64, slots)
	heContext.encoder.Decode(ptResult, resultVec)

	// Expected results for a good ReLU approximation (not perfect but close)
	for i, val := range testValues {
		expected := 0.0
		if val > 0 {
			expected = val
		}

		// Allow some approximation error
		if i < len(resultVec) {
			error := resultVec[i] - expected
			fmt.Printf("ReLU(%f) = %f (expected ~%f, error: %f)\n",
				val, resultVec[i], expected, error)

			// For positive values, expect reasonable approximation
			if val > 0 && (resultVec[i] < 0 || resultVec[i] > val*1.5) {
				t.Errorf("ReLU approximation too far off for %f: got %f", val, resultVec[i])
			}

			// For negative values, expect small positive value
			if val < 0 && resultVec[i] > 0.5 {
				t.Errorf("ReLU approximation too far off for %f: got %f", val, resultVec[i])
			}
		}
	}
}
package split

import (
	"fmt"
	"math/rand"
	"sync"
	"time"

	"github.com/tuneinsight/lattigo/v6/core/rlwe"
)

// Struct to store performance timing metrics
type TimingMetrics struct {
	totalEncryptionTime     time.Duration
	totalServerForwardTime  time.Duration
	totalClientBackwardTime time.Duration
	totalServerBackwardTime time.Duration
	batchesProcessed        int
}

// Run is the main entry point for training and evaluation
func Run(cfg RunConfig) error {
	// Apply configuration to global settings
	ApplyConfig(&cfg)

	// Print configuration details
	PrintConfig(&cfg)

	// Set random seed
	rand.Seed(time.Now().UnixNano())

	// Initialize HE context
	fmt.Println("Initializing HE context...")
	heContext, err := initHE()
	if err != nil {
		return fmt.Errorf("failed to initialize HE context: %v", err)
	}

	// Load MNIST data
	fmt.Println("Loading MNIST data...")
	trainImages, trainLabels, testImages, testLabels, err := readMNISTData()
	if err != nil {
		return fmt.Errorf("failed to load MNIST data: %v", err)
	}

	var clientModelObj *ClientModel
	var serverModelObj *ServerModel

	// Initialize or load models based on mode
	if cfg.Mode == "eval" {
		fmt.Printf("Loading models from %s and %s...\n", cfg.ClientPath, cfg.ServerPath)
		clientModelObj, serverModelObj, err = loadModel(cfg.ClientPath, cfg.ServerPath)
		if err != nil {
			return fmt.Errorf("failed to load models: %v", err)
		}
	} else {
		// Initialize new models
		fmt.Println("Initializing models...")
		clientModelObj = initClientModel(cfg.ModelCfg)
		serverModelObj = initServerModel(cfg.ModelCfg)
	}

	// Training or evaluation based on mode
	if cfg.Mode != "eval" {
		fmt.Printf("Starting training with %d batches...\n", cfg.NumBatches)

		// Choose which training method to use
		if cfg.FullyHE {
			// Use fully homomorphic training
			fmt.Println("Using fully homomorphic training...")
			trainModelWithBatches(heContext, clientModelObj, serverModelObj,
				trainImages, trainLabels, Epochs, BatchSize, LearningRate, cfg.NumBatches, true)
		} else if cfg.FullySIMD {
			// Use fully optimized SIMD training
			fmt.Println("Using fully optimized SIMD training...")
			trainModelFullSIMD(heContext, clientModelObj, serverModelObj,
				trainImages, trainLabels, Epochs, BatchSize, LearningRate, cfg.NumBatches)
		} else {
			// Use standard training
			fmt.Println("Using standard training...")
			trainModelWithBatches(heContext, clientModelObj, serverModelObj,
				trainImages, trainLabels, Epochs, BatchSize, LearningRate, cfg.NumBatches, false)
		}

		if cfg.SaveModels {
			fmt.Printf("Saving models to %s and %s...\n", cfg.ClientPath, cfg.ServerPath)
			err = saveModel(clientModelObj, serverModelObj, cfg.ClientPath, cfg.ServerPath)
			if err != nil {
				fmt.Printf("Failed to save models: %v\n", err)
			}
		}
	}

	// Evaluate the model
	if cfg.Mode != "train" {
		fmt.Println("Evaluating model...")
		accuracy := evaluateModel(heContext, clientModelObj, serverModelObj, testImages, testLabels)
		fmt.Printf("Test accuracy: %.2f%%\n", accuracy*100)
	}

	fmt.Println("Done.")
	return nil
}

// Trains the split learning model with a limited number of batches
func trainModelWithBatches(heContext *HEContext, clientModel *ClientModel, serverModel *ServerModel,
	images [][]float64, labels []int, epochs int, batchSize int, learningRate float64, maxBatches int, fullyHomomorphic bool) {

	numSamples := len(images)
	numBatches := numSamples / batchSize

	// Limit the number of batches
	if maxBatches > 0 && maxBatches < numBatches {
		numBatches = maxBatches
	}

	metrics := &TimingMetrics{}

	// Log the training mode
	if fullyHomomorphic {
		fmt.Println("Using fully homomorphic backpropagation mode...")
	} else {
		fmt.Println("Using standard homomorphic mode...")
	}

	for epoch := 0; epoch < epochs; epoch++ {
		fmt.Printf("Epoch %d/%d\n", epoch+1, epochs)

		// Shuffle data
		indices := rand.Perm(numSamples)

		epochStart := time.Now()

		// Process each batch
		for batch := 0; batch < numBatches; batch++ {
			if batch%10 == 0 {
				fmt.Printf("  Batch %d/%d\n", batch+1, numBatches)
			}

			// Get batch indices
			startIdx := batch * batchSize
			endIdx := startIdx + batchSize
			batchIndices := indices[startIdx:endIdx]

			// Choose which training method to use
			if fullyHomomorphic {
				// Train using fully homomorphic backpropagation
				err := trainBatchFullHomomorphic(heContext, clientModel, serverModel, images, labels, batchIndices, learningRate)
				if err != nil {
					fmt.Printf("Error in fully homomorphic training: %v\n", err)
					continue
				}
			} else {
				// Train using the standard method with timing
				trainBatchWithTiming(heContext, clientModel, serverModel, images, labels, batchIndices, learningRate, metrics)
			}
		}

		epochDuration := time.Since(epochStart)
		fmt.Printf("Epoch completed in %v\n", epochDuration)
	}

	// Print timing metrics only for standard mode
	if !fullyHomomorphic && metrics.batchesProcessed > 0 {
		fmt.Println("\nPerformance Metrics:")
		fmt.Printf("  Average encryption time: %v/batch\n",
			metrics.totalEncryptionTime/time.Duration(metrics.batchesProcessed))
		fmt.Printf("  Average server forward time: %v/batch\n",
			metrics.totalServerForwardTime/time.Duration(metrics.batchesProcessed))
		fmt.Printf("  Average client computation time: %v/batch\n",
			metrics.totalClientBackwardTime/time.Duration(metrics.batchesProcessed))
		fmt.Printf("  Average server backward time: %v/batch\n",
			metrics.totalServerBackwardTime/time.Duration(metrics.batchesProcessed))

		totalTime := metrics.totalEncryptionTime + metrics.totalServerForwardTime +
			metrics.totalClientBackwardTime + metrics.totalServerBackwardTime
		fmt.Printf("  Total processing time: %v\n", totalTime)
		fmt.Printf("  Average batch processing time: %v/batch\n",
			totalTime/time.Duration(metrics.batchesProcessed))
	}
}

// Trains the model on a single batch with timing measurements
func trainBatchWithTiming(heContext *HEContext, clientModel *ClientModel, serverModel *ServerModel,
	images [][]float64, labels []int, batchIndices []int, learningRate float64, metrics *TimingMetrics) {

	// Check if metrics is nil
	trackMetrics := metrics != nil

	// Phase 1: Client-Side Prep and Forward to Server
	encStart := time.Now()
	encInputs, err := clientPrepareAndEncryptBatch(heContext, images, batchIndices)
	encTime := time.Since(encStart)
	if trackMetrics {
		metrics.totalEncryptionTime += encTime
	}

	if err != nil {
		fmt.Printf("Error in client preparation: %v\n", err)
		return
	}

	// Phase 2: Server-Side Homomorphic Forward Pass
	serverStart := time.Now()
	encActivations, err := serverForwardPass(heContext, serverModel, encInputs)
	serverTime := time.Since(serverStart)
	if trackMetrics {
		metrics.totalServerForwardTime += serverTime
	}

	if err != nil {
		fmt.Printf("Error in server forward pass: %v\n", err)
		return
	}

	// Phase 3: Client-Side Plaintext Computation (Forward & Backward)
	clientStart := time.Now()
	encGradients, err := clientForwardAndBackward(heContext, clientModel, encActivations, labels, batchIndices)
	clientTime := time.Since(clientStart)
	if trackMetrics {
		metrics.totalClientBackwardTime += clientTime
	}

	if err != nil {
		fmt.Printf("Error in client forward and backward: %v\n", err)
		return
	}

	// Phase 4: Server-Side Homomorphic Backward Pass & Update
	serverBackStart := time.Now()
	// Pass the cached encInputs to serverBackwardAndUpdate for accurate weight updates
	err = serverBackwardAndUpdate(heContext, serverModel, encGradients, encInputs, learningRate)
	serverBackTime := time.Since(serverBackStart)
	if trackMetrics {
		metrics.totalServerBackwardTime += serverBackTime
		metrics.batchesProcessed++
	}

	if err != nil {
		fmt.Printf("Error in server backward and update: %v\n", err)
		return
	}
}

// trainBatchFullHomomorphic performs fully homomorphic training on a single batch
func trainBatchFullHomomorphic(heContext *HEContext, clientModel *ClientModel, serverModel *ServerModel,
	images [][]float64, labels []int, batchIndices []int, learningRate float64) error {

	// 1. Client: Prepare and encrypt the batch
	encInputs, err := clientPrepareAndEncryptBatch(heContext, images, batchIndices)
	if err != nil {
		return fmt.Errorf("client encryption error: %v", err)
	}

	// 2. Server: Forward pass
	encActivations, err := serverForwardPass(heContext, serverModel, encInputs)
	if err != nil {
		return fmt.Errorf("server forward pass error: %v", err)
	}

	// 3. Client: Forward and backward pass (now returns packed gradients)
	encGradBlk, err := clientForwardAndBackward(heContext, clientModel, encActivations, labels, batchIndices)
	if err != nil {
		return fmt.Errorf("client forward/backward error: %v", err)
	}

	// 4. Server: Fully homomorphic backward pass and weight update using packed SIMD
	// We'll use serverBackwardAndUpdate which handles the packed format correctly
	err = serverBackwardAndUpdate(heContext, serverModel, encGradBlk, encInputs, learningRate)
	if err != nil {
		return fmt.Errorf("homomorphic backward error: %v", err)
	}

	// 5. We don't need to manually convert back the model since serverBackwardAndUpdate
	// already updates the serverModel directly

	return nil
}

// Trains the model on a single batch (wrapper for backward compatibility)
func trainBatch(heContext *HEContext, clientModel *ClientModel, serverModel *ServerModel,
	images [][]float64, labels []int, batchIndices []int, learningRate float64) {

	// Call the timing version with nil metrics to ignore timing
	trainBatchWithTiming(heContext, clientModel, serverModel, images, labels, batchIndices, learningRate, nil)
}

// Trains the split learning model with timing metrics
func trainModel(heContext *HEContext, clientModel *ClientModel, serverModel *ServerModel,
	images [][]float64, labels []int, epochs int, batchSize int, learningRate float64) {

	// Call the version with unlimited batches and standard mode
	trainModelWithBatches(heContext, clientModel, serverModel, images, labels, epochs, batchSize, learningRate, 0, false)
}

// Trains the split learning model with a limited number of batches
// This version fully utilizes SIMD by keeping the server model in encrypted form
func trainModelFullSIMD(heContext *HEContext, clientModel *ClientModel, serverModel *ServerModel,
	images [][]float64, labels []int, epochs int, batchSize int, learningRate float64, maxBatches int) {

	numSamples := len(images)
	numBatches := numSamples / batchSize

	// Limit the number of batches
	if maxBatches > 0 && maxBatches < numBatches {
		numBatches = maxBatches
	}

	// Create a packed server model for SIMD operations - will keep this throughout training
	fmt.Println("Converting server model to packed form...")
	heServer, err := convertToPacked(serverModel, heContext)
	if err != nil {
		fmt.Printf("Failed to convert to packed model: %v\n", err)
		return
	}

	fmt.Println("Using fully optimized SIMD mode for training...")

	metrics := &TimingMetrics{}

	for epoch := 0; epoch < epochs; epoch++ {
		fmt.Printf("Epoch %d/%d\n", epoch+1, epochs)

		// Shuffle data
		indices := rand.Perm(numSamples)

		epochStart := time.Now()

		// Process each batch
		for batch := 0; batch < numBatches; batch++ {
			if batch%10 == 0 {
				fmt.Printf("  Batch %d/%d\n", batch+1, numBatches)
			}

			// Get batch indices
			startIdx := batch * batchSize
			endIdx := startIdx + batchSize
			batchIndices := indices[startIdx:endIdx]

			// Phase 1: Client-Side Prep and Forward to Server
			encStart := time.Now()
			encInputs, err := clientPrepareAndEncryptBatch(heContext, images, batchIndices)
			encTime := time.Since(encStart)
			metrics.totalEncryptionTime += encTime

			if err != nil {
				fmt.Printf("Error in client preparation: %v\n", err)
				continue
			}

			// Phase 2: Server-Side Homomorphic Forward Pass with packed model
			serverStart := time.Now()
			encActivations, err := serverForwardPassPacked(heContext, heServer, encInputs)
			serverTime := time.Since(serverStart)
			metrics.totalServerForwardTime += serverTime

			if err != nil {
				fmt.Printf("Error in server forward pass: %v\n", err)
				continue
			}

			// Phase 3: Client-Side Plaintext Computation (Forward & Backward)
			clientStart := time.Now()
			encGradients, err := clientForwardAndBackward(heContext, clientModel, encActivations, labels, batchIndices)
			clientTime := time.Since(clientStart)
			metrics.totalClientBackwardTime += clientTime

			if err != nil {
				fmt.Printf("Error in client forward and backward: %v\n", err)
				continue
			}

			// Phase 4: Server-Side Homomorphic Backward Pass & Update packed model directly
			serverBackStart := time.Now()
			err = packedUpdateDirect(heContext, heServer, encInputs, encGradients, learningRate, batchSize)
			serverBackTime := time.Since(serverBackStart)
			metrics.totalServerBackwardTime += serverBackTime
			metrics.batchesProcessed++

			if err != nil {
				fmt.Printf("Error in server backward and update: %v\n", err)
				continue
			}
		}

		epochDuration := time.Since(epochStart)
		fmt.Printf("Epoch completed in %v\n", epochDuration)
	}

	// Only decrypt and update the model at the end of training
	fmt.Println("Training complete. Converting model back to plaintext...")
	updateCompleteModelFromHE(heContext, serverModel, heServer, batchSize)

	// Print timing metrics
	if metrics.batchesProcessed > 0 {
		fmt.Println("\nPerformance Metrics:")
		fmt.Printf("  Average encryption time: %v/batch\n",
			metrics.totalEncryptionTime/time.Duration(metrics.batchesProcessed))
		fmt.Printf("  Average server forward time: %v/batch\n",
			metrics.totalServerForwardTime/time.Duration(metrics.batchesProcessed))
		fmt.Printf("  Average client computation time: %v/batch\n",
			metrics.totalClientBackwardTime/time.Duration(metrics.batchesProcessed))
		fmt.Printf("  Average server backward time: %v/batch\n",
			metrics.totalServerBackwardTime/time.Duration(metrics.batchesProcessed))

		totalTime := metrics.totalEncryptionTime + metrics.totalServerForwardTime +
			metrics.totalClientBackwardTime + metrics.totalServerBackwardTime
		fmt.Printf("  Total processing time: %v\n", totalTime)
		fmt.Printf("  Average batch processing time: %v/batch\n",
			totalTime/time.Duration(metrics.batchesProcessed))
	}
}

// Forward pass using directly the packed server model (avoids repeated packing)
func serverForwardPassPacked(he *HEContext, heServer *HEServerPacked, encInputs []*rlwe.Ciphertext) ([]*rlwe.Ciphertext, error) {
	// Check if input is valid
	if len(encInputs) == 0 || encInputs[0] == nil {
		return nil, fmt.Errorf("invalid input: empty or nil encInputs")
	}

	// Number of images in the batch
	batchSize := len(encInputs)

	// Process each image separately
	resultOutputs := make([]*rlwe.Ciphertext, batchSize)

	// For each image in the batch
	for batchIdx := 0; batchIdx < batchSize; batchIdx++ {
		// Process each layer in the server model
		currentLayerOutput := encInputs[batchIdx : batchIdx+1] // Slice with single ciphertext

		for l := 0; l < len(heServer.W); l++ {
			serverArch := heServer.Config.Arch
			inputDim := serverArch[l]
			outputDim := serverArch[l+1]

			// Calculate the number of blocks needed for the output neurons
			neuronsPerCT := heServer.NeuronsPerCT
			numBlocks := (outputDim + neuronsPerCT - 1) / neuronsPerCT

			// Prepare the next layer activations
			nextLayer := make([]*rlwe.Ciphertext, numBlocks)

			// Create a mutex for thread-safe access to shared resources
			var mutex sync.Mutex

			// Process each block of neurons in parallel
			parallelFor(0, numBlocks, func(b int) {
				// Initialize with bias for this neuron block
				blockResult := heServer.b[l][b].CopyNew()

				// Get the input for this image
				encInput := currentLayerOutput[0]

				// For each input dimension, multiply by weight and add to accumulator
				for i := 0; i < inputDim; i++ {
					// Create a temporary ciphertext for this multiplication
					temp := encInput.CopyNew()

					// Multiply the input by the weight for this neuron block
					he.evaluator.Mul(temp, heServer.W[l][i][b], temp)

					// Relinearize
					he.evaluator.Relinearize(temp, temp)

					// Add to the accumulator
					he.evaluator.Add(blockResult, temp, blockResult)
				}

				// Apply ReLU approximation to this block's activation
				activatedBlock, err := applyReLU(he, blockResult)
				if err != nil {
					fmt.Printf("Error in ReLU for block %d: %v\n", b, err)
					return
				}

				// Safely store the result
				mutex.Lock()
				nextLayer[b] = activatedBlock
				mutex.Unlock()
			})

			// Update current layer for the next iteration
			currentLayerOutput = nextLayer
		}

		// Store the final output for this image
		resultOutputs[batchIdx] = currentLayerOutput[0]
	}

	return resultOutputs, nil
}

// Update packed model directly without decrypting after each batch
func packedUpdateDirect(heContext *HEContext, heServer *HEServerPacked, encInputs []*rlwe.Ciphertext,
	encGradients []*rlwe.Ciphertext, learningRate float64, batchSize int) error {

	// Process only the first (last) layer of the server model
	// In future versions, this could be extended to all server layers
	l := len(heServer.W) - 1
	serverArch := heServer.Config.Arch
	inputDim := serverArch[l]
	outputDim := serverArch[l+1]

	// Prepare LR plaintext
	lrPt := scalarPlain(-1.0*learningRate/float64(batchSize), heContext.params, heContext.encoder)

	// Calculate how many neurons per ciphertext
	neuronsPerCT := heServer.NeuronsPerCT
	numBlocks := (outputDim + neuronsPerCT - 1) / neuronsPerCT

	// Check if we have the right number of gradient blocks
	if len(encGradients) != numBlocks {
		return fmt.Errorf("gradient blocks mismatch: got %d, expected %d", len(encGradients), numBlocks)
	}

	// Process each block of neurons in parallel
	var wg sync.WaitGroup
	var errMutex sync.Mutex
	var packedErr error

	for b := 0; b < numBlocks; b++ {
		wg.Add(1)
		go func(blockIdx int) {
			defer wg.Done()

			// For each input dimension
			for i := 0; i < inputDim; i++ {
				// 1. Create a copy of the input
				inputCopy := encInputs[0].CopyNew()

				// 2. Perform inner sum across the batch dimension
				summedInput, err := sumSlotsWithRotations(heContext, inputCopy, batchSize)
				if err != nil {
					errMutex.Lock()
					packedErr = fmt.Errorf("error in inner sum for block %d: %v", blockIdx, err)
					errMutex.Unlock()
					return
				}

				// 3. Create a copy of the gradient
				gradCopy := encGradients[blockIdx].CopyNew()

				// 4. Multiply gradient with input
				if err := heContext.evaluator.Mul(gradCopy, summedInput, gradCopy); err != nil {
					errMutex.Lock()
					packedErr = fmt.Errorf("error in gradient-input multiplication for block %d: %v", blockIdx, err)
					errMutex.Unlock()
					return
				}

				// 5. Scale by learning rate
				if err := heContext.evaluator.Mul(gradCopy, lrPt, gradCopy); err != nil {
					errMutex.Lock()
					packedErr = fmt.Errorf("error in learning rate scaling for block %d: %v", blockIdx, err)
					errMutex.Unlock()
					return
				}

				// 6. Add to the weights
				if err := heContext.evaluator.Add(heServer.W[l][i][blockIdx], gradCopy, heServer.W[l][i][blockIdx]); err != nil {
					errMutex.Lock()
					packedErr = fmt.Errorf("error updating weights for block %d: %v", blockIdx, err)
					errMutex.Unlock()
					return
				}
			}

			// Update biases
			// 1. Create a copy of the gradient
			gradCopy := encGradients[blockIdx].CopyNew()

			// 2. Sum across batch dimension
			summedGrad, err := sumSlotsWithRotations(heContext, gradCopy, batchSize)
			if err != nil {
				errMutex.Lock()
				packedErr = fmt.Errorf("error in inner sum for biases in block %d: %v", blockIdx, err)
				errMutex.Unlock()
				return
			}

			// 3. Scale by learning rate
			if err := heContext.evaluator.Mul(summedGrad, lrPt, summedGrad); err != nil {
				errMutex.Lock()
				packedErr = fmt.Errorf("error in learning rate scaling for biases in block %d: %v", blockIdx, err)
				errMutex.Unlock()
				return
			}

			// 4. Add to the biases
			if err := heContext.evaluator.Add(heServer.b[l][blockIdx], summedGrad, heServer.b[l][blockIdx]); err != nil {
				errMutex.Lock()
				packedErr = fmt.Errorf("error updating biases for block %d: %v", blockIdx, err)
				errMutex.Unlock()
				return
			}
		}(b)
	}

	wg.Wait()

	if packedErr != nil {
		return packedErr
	}

	return nil
}

// Update the complete model from packed HE model - only call at end of training
func updateCompleteModelFromHE(heContext *HEContext, serverModel *ServerModel, heServer *HEServerPacked, batchSize int) {
	// For each layer
	for l := 0; l < len(serverModel.Weights); l++ {
		// Call the layer-specific update function
		updateModelFromHE(heContext, serverModel, heServer, l, batchSize)
	}
}
package split

import (
	"testing"
)

// setTestBatchSize sets the global BatchSize for a test and returns a function to restore the original value
func setTestBatchSize(size int) func() {
	original := BatchSize
	BatchSize = size
	return func() {
		BatchSize = original
	}
}

func TestSimpleTraining(t *testing.T) {
	// Set batch size for this test
	restore := setTestBatchSize(2)
	defer restore()

	// Initialize HE context
	heContext, err := initHE()
	if err != nil {
		t.Fatalf("Failed to initialize HE context: %v", err)
	}

	// Create dummy data - 2 small images (3x3 instead of 28x28)
	// We'll just use 9 pixels for testing
	smallInputDim := 9
	images := make([][]float64, 2)
	for i := range images {
		images[i] = make([]float64, smallInputDim)
		for j := range images[i] {
			images[i][j] = float64(i+j) / 10.0 // Simple pattern
		}
	}
	labels := []int{0, 1} // Simple labels

	// Create configuration with consistent hidden layer dimensions
	config := &ModelConfig{
		Arch:     []int{smallInputDim, 32, 32, OutputDim},
		SplitIdx: 1, // Split after the first hidden layer
	}

	// Create client and server models using the initialization functions
	// which will allocate the correct dimensions based on the configuration
	clientModel := initClientModel(config)
	serverModel := initServerModel(config)

	// Test batch indices
	batchIndices := []int{0}

	// Run both training methods
	t.Log("Testing standard training...")
	trainBatchWithTiming(heContext, clientModel, serverModel, images, labels, batchIndices, 0.01, nil)

	t.Log("Testing fully homomorphic training...")
	err = trainBatchFullHomomorphic(heContext, clientModel, serverModel, images, labels, batchIndices, 0.01)
	if err != nil {
		t.Fatalf("Error in fully homomorphic training: %v", err)
	}

	t.Log("Both training methods completed successfully")
}

func TestServerWithFirstLayerBatchPerCiphertext(t *testing.T) {
	// Set batch size for this test
	restore := setTestBatchSize(2)
	defer restore()

	// Initialize HE context
	heContext, err := initHE()
	if err != nil {
		t.Fatalf("Failed to initialize HE context: %v", err)
	}

	// Use real MNIST data but only the first few images
	images, labels, _, _, err := readMNISTData()
	if err != nil {
		t.Fatalf("Failed to load MNIST data: %v", err)
	}

	// Create configuration - server has the first layer and activation
	// Use HiddenDim2=32 for both hidden layers to avoid dimension mismatch warnings
	config := &ModelConfig{
		Arch:     []int{MnistPixels, 32, 32, OutputDim},
		SplitIdx: 1, // Server has 1 layer (input -> hidden1)
	}

	// Create client and server models
	clientModel := initClientModel(config)
	serverModel := initServerModel(config)

	// Test with very small batch size to ensure each image fits in a ciphertext
	batchSize := BatchSize
	batchIndices := []int{0, 1}

	// Test the forward pass first to isolate issues
	t.Log("Testing forward pass with batch per ciphertext...")

	// Prepare and encrypt the batch
	encInputs, err := clientPrepareAndEncryptBatch(heContext, images, batchIndices)
	if err != nil {
		t.Fatalf("Failed to prepare and encrypt batch: %v", err)
	}

	// Verify we have the right number of ciphertexts (one per image)
	if len(encInputs) != batchSize {
		t.Fatalf("Expected %d ciphertexts, got %d", batchSize, len(encInputs))
	}

	// Run server forward pass
	encActivations, err := serverForwardPass(heContext, serverModel, encInputs)
	if err != nil {
		t.Fatalf("Failed in server forward pass: %v", err)
	}

	// Run client forward and backward pass
	_, err = clientForwardAndBackward(heContext, clientModel, encActivations, labels, batchIndices)
	if err != nil {
		t.Fatalf("Failed in client forward and backward: %v", err)
	}

	// Run full training batch to ensure everything works together
	t.Log("Testing full training with batch per ciphertext...")
	trainBatchWithTiming(heContext, clientModel, serverModel, images, labels, batchIndices, 0.01, nil)

	t.Log("Training completed successfully with batch per ciphertext")
}

func TestSimpleWeightStructure(t *testing.T) {
	// Set batch size for this test
	restore := setTestBatchSize(2)
	defer restore()

	// Initialize HE context
	heContext, err := initHE()
	if err != nil {
		t.Fatalf("Failed to initialize HE context: %v", err)
	}

	// Create a very small configuration with just a few neurons
	config := &ModelConfig{
		Arch:     []int{4, 2, 2}, // Tiny architecture for testing
		SplitIdx: 1,              // Server has 1 layer
	}

	// Create tiny client model
	clientModel := &ClientModel{
		Weights: make([][][]float64, 1), // Only one layer
		Biases:  make([][]float64, 1),
		Config:  config,
	}

	// Initialize client layer weights
	clientModel.Weights[0] = make([][]float64, 2) // 2 inputs from the server
	clientModel.Weights[0][0] = make([]float64, 2)
	clientModel.Weights[0][1] = make([]float64, 2)
	// Set some values
	clientModel.Weights[0][0][0] = 0.1
	clientModel.Weights[0][0][1] = 0.2
	clientModel.Weights[0][1][0] = 0.3
	clientModel.Weights[0][1][1] = 0.4

	// Initialize client biases
	clientModel.Biases[0] = make([]float64, 2)
	clientModel.Biases[0][0] = 0.01
	clientModel.Biases[0][1] = 0.02

	// Create tiny server model
	serverModel := &ServerModel{
		Weights: make([][][]float64, 1), // Only one layer
		Biases:  make([][]float64, 1),
		Config:  config,
	}

	// Initialize server layer weights
	serverModel.Weights[0] = make([][]float64, 4) // 4 inputs
	for i := range serverModel.Weights[0] {
		serverModel.Weights[0][i] = make([]float64, 2)
		for j := range serverModel.Weights[0][i] {
			serverModel.Weights[0][i][j] = 0.1 * float64(i+j+1)
		}
	}

	// Initialize server biases
	serverModel.Biases[0] = make([]float64, 2)
	serverModel.Biases[0][0] = 0.01
	serverModel.Biases[0][1] = 0.02

	// Create very simple 4-pixel "images"
	images := make([][]float64, 2)
	for i := range images {
		images[i] = make([]float64, 4)
		for j := range images[i] {
			images[i][j] = float64(i+j) / 10.0
		}
	}
	labels := []int{0, 1}

	batchIndices := []int{0, 1}

	// Test the forward pass
	t.Log("Testing weight structure with simple network...")

	// Prepare and encrypt the batch
	encInputs, err := clientPrepareAndEncryptBatch(heContext, images, batchIndices)
	if err != nil {
		t.Fatalf("Failed to prepare and encrypt batch: %v", err)
	}

	// Run server forward pass
	encActivations, err := serverForwardPass(heContext, serverModel, encInputs)
	if err != nil {
		t.Fatalf("Failed in server forward pass: %v", err)
	}

	// Run client forward and backward pass
	_, err = clientForwardAndBackward(heContext, clientModel, encActivations, labels, batchIndices)
	if err != nil {
		t.Fatalf("Failed in client forward and backward: %v", err)
	}

	t.Log("Simple weight structure test passed")
}

func TestModelDimensions(t *testing.T) {
	// Create a test configuration
	config := &ModelConfig{
		Arch:     []int{784, 128, 64, 10}, // MNIST dimensions
		SplitIdx: 1,                       // Server has first layer
	}

	// Initialize client and server models
	clientModel := initClientModel(config)
	serverModel := initServerModel(config)

	// Check server model dimensions
	if len(serverModel.Weights) != 1 {
		t.Errorf("Expected server to have 1 layer, got %d", len(serverModel.Weights))
	}

	if len(serverModel.Weights[0]) != 784 {
		t.Errorf("Expected server input dimension to be 784, got %d", len(serverModel.Weights[0]))
	}

	if len(serverModel.Weights[0][0]) != 128 {
		t.Errorf("Expected server output dimension to be 128, got %d", len(serverModel.Weights[0][0]))
	}

	// Check client model dimensions
	if len(clientModel.Weights) != 2 {
		t.Errorf("Expected client to have 2 layers, got %d", len(clientModel.Weights))
	}

	if len(clientModel.Weights[0]) != 128 {
		t.Errorf("Expected client first layer input dimension to be 128, got %d", len(clientModel.Weights[0]))
	}

	if len(clientModel.Weights[0][0]) != 64 {
		t.Errorf("Expected client first layer output dimension to be 64, got %d", len(clientModel.Weights[0][0]))
	}

	if len(clientModel.Weights[1]) != 64 {
		t.Errorf("Expected client second layer input dimension to be 64, got %d", len(clientModel.Weights[1]))
	}

	if len(clientModel.Weights[1][0]) != 10 {
		t.Errorf("Expected client second layer output dimension to be 10, got %d", len(clientModel.Weights[1][0]))
	}

	// Verify GetLayerInputDim and GetLayerOutputDim match actual dimensions
	for l := 0; l < len(serverModel.Weights); l++ {
		inputDim := serverModel.GetLayerInputDim(l)
		if inputDim != len(serverModel.Weights[l]) {
			t.Errorf("Server layer %d: GetLayerInputDim returned %d but weights dimension is %d",
				l, inputDim, len(serverModel.Weights[l]))
		}

		outputDim := serverModel.GetLayerOutputDim(l)
		if outputDim != len(serverModel.Weights[l][0]) {
			t.Errorf("Server layer %d: GetLayerOutputDim returned %d but weights dimension is %d",
				l, outputDim, len(serverModel.Weights[l][0]))
		}
	}

	for l := 0; l < len(clientModel.Weights); l++ {
		inputDim := clientModel.GetLayerInputDim(l)
		if inputDim != len(clientModel.Weights[l]) {
			t.Errorf("Client layer %d: GetLayerInputDim returned %d but weights dimension is %d",
				l, inputDim, len(clientModel.Weights[l]))
		}

		outputDim := clientModel.GetLayerOutputDim(l)
		if outputDim != len(clientModel.Weights[l][0]) {
			t.Errorf("Client layer %d: GetLayerOutputDim returned %d but weights dimension is %d",
				l, outputDim, len(clientModel.Weights[l][0]))
		}
	}

	t.Log("Model dimensions match configuration as expected")
}
package split

import (
	"github.com/tuneinsight/lattigo/v6/core/rlwe"
	"github.com/tuneinsight/lattigo/v6/schemes/ckks"
)

// Helper function to find the minimum of two integers
func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

// innerSumSlots returns a ciphertext that contains the slot-sum of ct
// replicated in every slot. Uses Lattigo's more efficient InnerSum
// which provides an O(log n) tree reduction rather than linear rotations.
func innerSumSlots(ct *rlwe.Ciphertext, slots int, evaluator *ckks.Evaluator) (*rlwe.Ciphertext, error) {
	// Use Lattigo's optimized InnerSum for O(log n) reduction
	// This creates rotations in a tree pattern rather than linearly
	res := ct.CopyNew()
	if err := evaluator.InnerSum(res, 1, slots, res); err != nil {
		return nil, err
	}
	return res, nil
}

// scalarPlain creates a plaintext with all slots set to the same value
func scalarPlain(value float64, params ckks.Parameters, encoder *ckks.Encoder) *rlwe.Plaintext {
	pt := ckks.NewPlaintext(params, params.MaxLevel())

	// Create a vector with all slots having the same value
	vec := make([]float64, params.N()/2)
	for i := range vec {
		vec[i] = value
	}

	// Encode the vector
	encoder.Encode(vec, pt)

	return pt
}

// repeat creates a slice with a value repeated n times
func repeat(value float64, n int) []float64 {
	result := make([]float64, n)
	for i := range result {
		result[i] = value
	}
	return result
}

// maskFirst creates a plaintext mask that keeps only the first few slots
// and zeros out the rest. This is useful for extracting just the first value
// from batch operations.
func maskFirst(params ckks.Parameters, encoder *ckks.Encoder, batchSize int) *rlwe.Plaintext {
	pt := ckks.NewPlaintext(params, params.MaxLevel())

	// Create a vector with 1s for the first batchSize slots and 0s elsewhere
	vec := make([]float64, params.N()/2)
	for i := 0; i < batchSize && i < len(vec); i++ {
		vec[i] = 1.0
	}

	// Encode the vector
	encoder.Encode(vec, pt)

	return pt
}

// chunkSum computes the sum across slots within specified chunks
// For example, it can sum across batch elements for each neuron
func chunkSum(ct *rlwe.Ciphertext, chunkSize int, evaluator *ckks.Evaluator) (*rlwe.Ciphertext, error) {
	// Use innerSumSlots for the efficient implementation
	return innerSumSlots(ct, chunkSize, evaluator)
}
